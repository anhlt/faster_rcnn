{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_rcnn.utils.datasets.voc.voc import VOCDetection\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from copy import copy\n",
    "import os\n",
    "from random import randint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, gt_boxes=[], predict_boxes = []):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    print(inp.shape)\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    fig,ax = plt.subplots(1, figsize=(20, 10))\n",
    "\n",
    "    ax.imshow(inp)\n",
    "    for i, box in enumerate(gt_boxes):\n",
    "        print(box)\n",
    "        rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1]  ,linewidth=2,edgecolor='r',facecolor='none')\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "    for i, box in enumerate(predict_boxes):\n",
    "        rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1]  ,linewidth=1,edgecolor='g',facecolor='none')\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import logging\n",
    "try:\n",
    "    from faster_rcnn.utils.datasets.voc.string_int_label_map_pb2 import StringIntLabelMap\n",
    "except Exception as e:\n",
    "    from string_int_label_map_pb2 import StringIntLabelMap\n",
    "\n",
    "from google.protobuf import text_format\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    import xml.etree.cElementTree as ET\n",
    "else:\n",
    "    import xml.etree.ElementTree as ET\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "class TransformVOCDetectionAnnotation(object):\n",
    "    def __init__(self, keep_difficult=False):\n",
    "        self.keep_difficult = keep_difficult\n",
    "\n",
    "    def __call__(self, target):\n",
    "        res = []\n",
    "\n",
    "        for obj in target.iter('object'):\n",
    "            name = obj.find('name').text\n",
    "            bb = obj.find('bndbox')\n",
    "            bndbox = [bb.find('xmin').text, bb.find('ymin').text,\n",
    "                      bb.find('xmax').text, bb.find('ymax').text]\n",
    "\n",
    "            res += [bndbox + [name]]\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "class VOCDetection(data.Dataset):\n",
    "    def __init__(self, root, image_set, transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.image_set = image_set\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        dataset_name = 'VOC2007'\n",
    "        self._annopath = os.path.join(\n",
    "            self.root, dataset_name, 'Annotations', '%s.xml')\n",
    "        self._imgpath = os.path.join(\n",
    "            self.root, dataset_name, 'JPEGImages', '%s.jpg')\n",
    "        self._imgsetpath = os.path.join(\n",
    "            self.root, dataset_name, 'ImageSets', 'Main', '%s.txt')\n",
    "        self._label_map_path = os.path.join(\n",
    "            self.root, dataset_name, 'pascal_label_map.pbtxt')\n",
    "\n",
    "        with open(self._label_map_path) as f:\n",
    "            label_map_string = f.read()\n",
    "            label_map = StringIntLabelMap()\n",
    "            try:\n",
    "                text_format.Merge(label_map_string, label_map)\n",
    "            except text_format.ParseError:\n",
    "                label_map.ParseFromString(label_map_string)\n",
    "\n",
    "        label_map_dict = {'__background__': 0}\n",
    "        self.classes = ['__background__']\n",
    "\n",
    "        for id, item in enumerate(label_map.item, 1):\n",
    "            label_map_dict[item.name] = id\n",
    "            self.classes.append(item.name)\n",
    "\n",
    "        self.label_map_dict = label_map_dict\n",
    "\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = transforms.Compose([\n",
    "#                 transforms.Resize(600),\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Normalize([0.485, 0.456, 0.406], [\n",
    "#                                      0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "        with open(self._imgsetpath % self.image_set) as f:\n",
    "            ids = f.readlines()\n",
    "\n",
    "        self.ids = []\n",
    "        for id in ids:\n",
    "            striped_strings = id.strip().split()\n",
    "            if len(striped_strings) == 2:\n",
    "                self.ids.append(striped_strings[0])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.ids[index]\n",
    "\n",
    "        try:\n",
    "            target = ET.parse(self._annopath % img_id).getroot()\n",
    "            img = Image.open(self._imgpath % img_id).convert('RGB')\n",
    "        except IOError as e:\n",
    "            logger.debug(e)\n",
    "            return None\n",
    "\n",
    "        origin_size = img.size\n",
    "        \n",
    "        \n",
    "        img = np.asarray(img, dtype=np.uint8)\n",
    "        target_size = tuple(img.shape)\n",
    "        im_info = np.array(\n",
    "            [[float(target_size[0]), float(target_size[1]), 1.]])\n",
    "\n",
    "        blobs = {}\n",
    "        blobs['tensor'] = img\n",
    "        blobs['im_info'] = im_info\n",
    "        blobs['im_name'] = os.path.basename(self._imgpath % img_id)\n",
    "\n",
    "        def bboxs(target):\n",
    "            for obj in target.iter('object'):\n",
    "                name = obj.find('name').text\n",
    "                bb = obj.find('bndbox')\n",
    "                bndbox = [bb.find('xmin').text, bb.find('ymin').text,\n",
    "                          bb.find('xmax').text, bb.find('ymax').text]\n",
    "                class_index = self.label_map_dict[name]\n",
    "                yield bndbox, class_index\n",
    "\n",
    "        try:\n",
    "            gt_boxes, gt_classes = zip(*[box for box in bboxs(target)])\n",
    "            gt_boxes = np.array(gt_boxes, dtype=np.uint16)\n",
    "            gt_classes = np.array(gt_classes, dtype=np.int32)\n",
    "        except ValueError as e:\n",
    "            return None\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        blobs['gt_classes'] = gt_classes\n",
    "        blobs['boxes'] = gt_boxes * im_info[0][2]\n",
    "\n",
    "        return blobs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def show(self, index):\n",
    "        img, target = self.__getitem__(index)\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        for obj in target:\n",
    "            draw.rectangle(obj[0:4], outline=(255, 0, 0))\n",
    "            draw.text(obj[0:2], obj[4], fill=(0, 255, 0))\n",
    "        img.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n"
     ]
    }
   ],
   "source": [
    "root = '/data'\n",
    "ds = VOCDetection(root, 'train')\n",
    "print(len(ds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0 __background__\n",
      "1 671\n"
     ]
    }
   ],
   "source": [
    "id_dict = dict(enumerate(ds.classes))\n",
    "print len(id_dict)\n",
    "for i ,v in id_dict.iteritems():\n",
    "    print i, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "js = json.dumps(dict(enumerate(ds.classes)))\n",
    "\n",
    "# Open new json file if not exist it will create\n",
    "with open('id.json', 'a') as fp:\n",
    "# write to json file\n",
    "    fp.write(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "/data/crop/671\n"
     ]
    }
   ],
   "source": [
    "crop_output_path = '/data/crop/'\n",
    "\n",
    "\n",
    "for key, item in enumerate(ds):\n",
    "    if key % 1000 == 0:\n",
    "        print key\n",
    "    \n",
    "    if item is None:\n",
    "        continue\n",
    "    im_data = item['tensor']\n",
    "    boxes = item['boxes']\n",
    "    gt_classes = item['gt_classes']\n",
    "    inp = im_data\n",
    "    im = Image.fromarray(inp)\n",
    "    flag = 0\n",
    "    for box, class_name  in zip(boxes,gt_classes) :\n",
    "        flag = 1\n",
    "        try:\n",
    "            copy_im = copy(im)\n",
    "            copy_im = copy_im.crop(box)\n",
    "            copy_im.show()\n",
    "            output_dir = os.path.join(crop_output_path, id_dict[class_name])\n",
    "            if not os.path.isdir(output_dir):\n",
    "                print output_dir\n",
    "                os.mkdir(output_dir)\n",
    "            copy_im.save(os.path.join(\n",
    "                    output_dir, str(randint(1, 10000)) + '.jpg'))\n",
    "        except Exception as e:\n",
    "            print e\n",
    "    if flag:\n",
    "        im.save(os.path.join(output_dir, 'origin' + str(randint(1, 10000)) + '.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.fromarray(inp.astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(ds[0]['tensor'][0], ds[0]['boxes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                crop_img = copy_image.crop((left, top, right, bottom))\n",
    "                crop_img.save(os.path.join(\n",
    "                    crop_output_path, str(randint(1, 10000)) + image_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
