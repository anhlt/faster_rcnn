{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "from scipy.misc import imread\n",
    "import matplotlib.patches as patches\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD, Adam\n",
    "import cv2\n",
    "from pycrayon import CrayonClient\n",
    "from torch.utils.data import DataLoader\n",
    "from faster_rcnn.network import  clip_gradient\n",
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data\n",
      "/data/data/mscoco\n",
      "loading annotations into memory...\n",
      "Done (t=10.60s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from faster_rcnn.utils.dataset import CocoData\n",
    "from faster_rcnn.utils.data_generator import CocoGenerator\n",
    "from faster_rcnn.utils.data_generator import Enqueuer\n",
    "\n",
    "dataDir = './data/mscoco'\n",
    "dataType = 'train2014'\n",
    "annFile='%s/annotations/instances_%s.json'%(dataDir,dataType)\n",
    "# pre_proposal_folder = './data/mscoco/coco_proposals/MCG/'\n",
    "\n",
    "images_dir = os.path.join(dataDir,'images', dataType)\n",
    "cap = CocoData(root = images_dir,\n",
    "                        annFile = annFile,\n",
    "#                         pre_proposal_folder=pre_proposal_folder,\n",
    "                        transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "\n",
    "data_gen = CocoGenerator(data=cap)\n",
    "queue = Enqueuer(generator=data_gen)\n",
    "queue.start(max_queue_size=10, workers=2)\n",
    "t = queue.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from faster_rcnn.faster_rcnn import  RPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = CrayonClient(hostname=\"crayon\", port=8889)\n",
    "try:\n",
    "    exp = cc.create_experiment(\"RPN\")\n",
    "except: \n",
    "    cc.remove_experiment(\"RPN\")\n",
    "    exp = cc.create_experiment(\"RPN\")\n",
    "\n",
    "disp_interval = 100\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPN (\n",
       "  (features): Sequential (\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU (inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU (inplace)\n",
       "    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU (inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU (inplace)\n",
       "    (9): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU (inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU (inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU (inplace)\n",
       "    (16): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU (inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU (inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU (inplace)\n",
       "    (23): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU (inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU (inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU (inplace)\n",
       "  )\n",
       "  (conv1): Conv2d (\n",
       "    (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu): ReLU (inplace)\n",
       "  )\n",
       "  (score_conv): Conv2d (\n",
       "    (conv): Conv2d(512, 18, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (bbox_conv): Conv2d (\n",
       "    (conv): Conv2d(512, 36, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = RPN()\n",
    "net.cuda()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = filter(lambda x: x.requires_grad, net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGD(param, lr=1e-4, momentum=0.9, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_gen, optimizer, model, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    losses = []\n",
    "    for step in range(1, epoch):\n",
    "#         blobs = data_gen.next()\n",
    "        blobs = cap[13499]\n",
    "        if blobs is None:\n",
    "            continue\n",
    "        if step > epoch:\n",
    "            break\n",
    "        im_data = blobs['data']\n",
    "        im_info = blobs['im_info']\n",
    "        gt_boxes = np.hstack([ blobs['boxes'] , blobs['gt_classes'][:, np.newaxis]])\n",
    "        gt_ishard = blobs['gt_ishard']\n",
    "        dontcare_areas = blobs['dontcare_areas']\n",
    "        output = model(im_data, im_info, gt_boxes, gt_ishard, dontcare_areas)\n",
    "        loss = model.loss\n",
    "        print 'loss', loss\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_gradient(model, 10.)\n",
    "        optimizer.step()\n",
    "        loss_value = loss.data.cpu().float()\n",
    "        losses.append(loss_value)\n",
    "        \n",
    "        if step % 1 == 0:\n",
    "\n",
    "            log_text = 'step %d, image: %s, loss: %.4f' % (\n",
    "                step, blobs['im_name'], train_loss /(step))\n",
    "            print(log_text)\n",
    "\n",
    "            re_cnt = True\n",
    "\n",
    "#         if step % log_interval == 0:\n",
    "#             exp.add_scalar_value('loss', loss.data[0], step=step)\n",
    "#             exp.add_scalar_value('last_layers_loss', net.loss.data[0], step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.9788996   2.18660808  4.41185856  6.25701904]\n",
      " [-2.43394184 -5.72291327 -2.19459772  3.81811428]\n",
      " [ 1.81119823 -0.13457787  1.13333988  2.26057553]\n",
      " ..., \n",
      " [ 0.21796353  4.62784815  1.43729854  3.76666594]\n",
      " [-0.26038569 -0.62148404 -0.41511074  1.4594512 ]\n",
      " [-4.65912867 -0.98074692  2.86140299  2.0340364 ]]\n",
      "rpn_cls_score.shape (1, 18, 37, 50)\n",
      "image info [[ 600.    800.      1.25]]\n",
      "anchors:\n",
      "[[ -84.  -40.   99.   55.]\n",
      " [-176.  -88.  191.  103.]\n",
      " [-360. -184.  375.  199.]\n",
      " [ -56.  -56.   71.   71.]\n",
      " [-120. -120.  135.  135.]\n",
      " [-248. -248.  263.  263.]\n",
      " [ -36.  -80.   51.   95.]\n",
      " [ -80. -168.   95.  183.]\n",
      " [-168. -344.  183.  359.]]\n",
      "anchor shapes:\n",
      "[[ 183.   95.]\n",
      " [ 367.  191.]\n",
      " [ 735.  383.]\n",
      " [ 127.  127.]\n",
      " [ 255.  255.]\n",
      " [ 511.  511.]\n",
      " [  87.  175.]\n",
      " [ 175.  351.]\n",
      " [ 351.  703.]]\n",
      "AnchorTargetLayer: height 37 width 50\n",
      "\n",
      "im_size: (600.0, 800.0)\n",
      "scale: 1.25\n",
      "height, width: (37, 50)\n",
      "rpn: gt_boxes.shape (3, 5)\n",
      "rpn: gt_boxes [[ 140.    253.75  185.    430.     24.  ]\n",
      " [ 318.75  247.5   442.5   388.75   24.  ]\n",
      " [ 397.5   242.5   571.25  395.     24.  ]]\n",
      "total_anchors 16650\n",
      "inds_inside 5944\n",
      "anchors.shape (5944, 4)\n",
      "cfg.TRAIN.RPN_FG_FRACTION , cfg.TRAIN.RPN_BATCHSIZE 0.75 512\n",
      "was 5376 inds, disabling 4877, now 499 inds\n",
      "means:\n",
      "[[-0.03129098 -0.0081403  -0.01392334  0.11795976]]\n",
      "stdevs:\n",
      "[[ 0.1062621   0.05485952  0.3766335   0.0689785 ]]\n",
      "---------------\n",
      "(5944,)\n",
      "(16650,)\n",
      "---------------\n",
      "rpn: max max_overlap 0.833974240567\n",
      "rpn: num_positive 13\n",
      "rpn: num_negative 499\n",
      "rpn: num_positive avg 13\n",
      "rpn: num_negative avg 499\n",
      "rpn_loss_box Variable containing:\n",
      " 227.1791\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "rpn_cross_entropy Variable containing:\n",
      " 6.5445\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "Variable containing:\n",
      " 6.5445\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 227.1791\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "loss Variable containing:\n",
      " 233.7236\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "step 1, image: COCO_train2014_000000309241.jpg, loss: 233.7236\n",
      "[[ 1.98235691  2.18271494  4.40476704  6.24733734]\n",
      " [-2.43050194 -5.71830559 -2.19273067  3.81773949]\n",
      " [ 1.81608844 -0.1410398   1.13044345  2.26312232]\n",
      " ..., \n",
      " [ 0.21199964  4.63739157  1.43481266  3.75932932]\n",
      " [-0.25361151 -0.61625564 -0.4187409   1.45904887]\n",
      " [-4.65974331 -0.98770589  2.85895658  2.04406238]]\n",
      "rpn_cls_score.shape (1, 18, 37, 50)\n",
      "image info [[ 600.    800.      1.25]]\n",
      "anchors:\n",
      "[[ -84.  -40.   99.   55.]\n",
      " [-176.  -88.  191.  103.]\n",
      " [-360. -184.  375.  199.]\n",
      " [ -56.  -56.   71.   71.]\n",
      " [-120. -120.  135.  135.]\n",
      " [-248. -248.  263.  263.]\n",
      " [ -36.  -80.   51.   95.]\n",
      " [ -80. -168.   95.  183.]\n",
      " [-168. -344.  183.  359.]]\n",
      "anchor shapes:\n",
      "[[ 183.   95.]\n",
      " [ 367.  191.]\n",
      " [ 735.  383.]\n",
      " [ 127.  127.]\n",
      " [ 255.  255.]\n",
      " [ 511.  511.]\n",
      " [  87.  175.]\n",
      " [ 175.  351.]\n",
      " [ 351.  703.]]\n",
      "AnchorTargetLayer: height 37 width 50\n",
      "\n",
      "im_size: (600.0, 800.0)\n",
      "scale: 1.25\n",
      "height, width: (37, 50)\n",
      "rpn: gt_boxes.shape (3, 5)\n",
      "rpn: gt_boxes [[ 140.    253.75  185.    430.     24.  ]\n",
      " [ 318.75  247.5   442.5   388.75   24.  ]\n",
      " [ 397.5   242.5   571.25  395.     24.  ]]\n",
      "total_anchors 16650\n",
      "inds_inside 5944\n",
      "anchors.shape (5944, 4)\n",
      "cfg.TRAIN.RPN_FG_FRACTION , cfg.TRAIN.RPN_BATCHSIZE 0.75 512\n",
      "was 5376 inds, disabling 4877, now 499 inds\n",
      "means:\n",
      "[[-0.03129098 -0.0081403  -0.01392334  0.11795976]]\n",
      "stdevs:\n",
      "[[ 0.1062621   0.05485952  0.3766335   0.0689785 ]]\n",
      "---------------\n",
      "(5944,)\n",
      "(16650,)\n",
      "---------------\n",
      "rpn: max max_overlap 0.833974240567\n",
      "rpn: num_positive 13\n",
      "rpn: num_negative 499\n",
      "rpn: num_positive avg 13\n",
      "rpn: num_negative avg 499\n",
      "rpn_loss_box Variable containing:\n",
      " 219.6982\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "rpn_cross_entropy Variable containing:\n",
      " 6.8892\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "Variable containing:\n",
      " 6.8892\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 219.6982\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "loss Variable containing:\n",
      " 226.5874\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "step 2, image: COCO_train2014_000000309241.jpg, loss: 230.1555\n",
      "[[ 1.98821366  2.17607498  4.39067221  6.23087692]\n",
      " [-2.42476797 -5.70857382 -2.18946409  3.81546283]\n",
      " [ 1.82523608 -0.15313968  1.12530172  2.26888299]\n",
      " ..., \n",
      " [ 0.20108068  4.65196037  1.4299767   3.743541  ]\n",
      " [-0.23863773 -0.60638672 -0.42562336  1.45808291]\n",
      " [-4.66029453 -0.99967951  2.85429358  2.0618782 ]]\n",
      "rpn_cls_score.shape (1, 18, 37, 50)\n",
      "image info [[ 600.    800.      1.25]]\n",
      "anchors:\n",
      "[[ -84.  -40.   99.   55.]\n",
      " [-176.  -88.  191.  103.]\n",
      " [-360. -184.  375.  199.]\n",
      " [ -56.  -56.   71.   71.]\n",
      " [-120. -120.  135.  135.]\n",
      " [-248. -248.  263.  263.]\n",
      " [ -36.  -80.   51.   95.]\n",
      " [ -80. -168.   95.  183.]\n",
      " [-168. -344.  183.  359.]]\n",
      "anchor shapes:\n",
      "[[ 183.   95.]\n",
      " [ 367.  191.]\n",
      " [ 735.  383.]\n",
      " [ 127.  127.]\n",
      " [ 255.  255.]\n",
      " [ 511.  511.]\n",
      " [  87.  175.]\n",
      " [ 175.  351.]\n",
      " [ 351.  703.]]\n",
      "AnchorTargetLayer: height 37 width 50\n",
      "\n",
      "im_size: (600.0, 800.0)\n",
      "scale: 1.25\n",
      "height, width: (37, 50)\n",
      "rpn: gt_boxes.shape (3, 5)\n",
      "rpn: gt_boxes [[ 140.    253.75  185.    430.     24.  ]\n",
      " [ 318.75  247.5   442.5   388.75   24.  ]\n",
      " [ 397.5   242.5   571.25  395.     24.  ]]\n",
      "total_anchors 16650\n",
      "inds_inside 5944\n",
      "anchors.shape (5944, 4)\n",
      "cfg.TRAIN.RPN_FG_FRACTION , cfg.TRAIN.RPN_BATCHSIZE 0.75 512\n",
      "was 5376 inds, disabling 4877, now 499 inds\n",
      "means:\n",
      "[[-0.03129098 -0.0081403  -0.01392334  0.11795976]]\n",
      "stdevs:\n",
      "[[ 0.1062621   0.05485952  0.3766335   0.0689785 ]]\n",
      "---------------\n",
      "(5944,)\n",
      "(16650,)\n",
      "---------------\n",
      "rpn: max max_overlap 0.833974240567\n",
      "rpn: num_positive 13\n",
      "rpn: num_negative 499\n",
      "rpn: num_positive avg 13\n",
      "rpn: num_negative avg 499\n",
      "rpn_loss_box Variable containing:\n",
      " 205.7062\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "rpn_cross_entropy Variable containing:\n",
      " 6.5018\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "Variable containing:\n",
      " 6.5018\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 205.7062\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "loss Variable containing:\n",
      " 212.2080\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "step 3, image: COCO_train2014_000000309241.jpg, loss: 224.1730\n",
      "[[ 1.9957      2.16729903  4.37172031  6.21093416]\n",
      " [-2.41784239 -5.69384336 -2.18421745  3.81120205]\n",
      " [ 1.83840382 -0.16967513  1.11883819  2.27945352]\n",
      " ..., \n",
      " [ 0.18809184  4.67058039  1.42327833  3.71964359]\n",
      " [-0.21380353 -0.59425461 -0.43393958  1.45802259]\n",
      " [-4.66149139 -1.01516867  2.84825492  2.08730078]]\n",
      "rpn_cls_score.shape (1, 18, 37, 50)\n",
      "image info [[ 600.    800.      1.25]]\n",
      "anchors:\n",
      "[[ -84.  -40.   99.   55.]\n",
      " [-176.  -88.  191.  103.]\n",
      " [-360. -184.  375.  199.]\n",
      " [ -56.  -56.   71.   71.]\n",
      " [-120. -120.  135.  135.]\n",
      " [-248. -248.  263.  263.]\n",
      " [ -36.  -80.   51.   95.]\n",
      " [ -80. -168.   95.  183.]\n",
      " [-168. -344.  183.  359.]]\n",
      "anchor shapes:\n",
      "[[ 183.   95.]\n",
      " [ 367.  191.]\n",
      " [ 735.  383.]\n",
      " [ 127.  127.]\n",
      " [ 255.  255.]\n",
      " [ 511.  511.]\n",
      " [  87.  175.]\n",
      " [ 175.  351.]\n",
      " [ 351.  703.]]\n",
      "AnchorTargetLayer: height 37 width 50\n",
      "\n",
      "im_size: (600.0, 800.0)\n",
      "scale: 1.25\n",
      "height, width: (37, 50)\n",
      "rpn: gt_boxes.shape (3, 5)\n",
      "rpn: gt_boxes [[ 140.    253.75  185.    430.     24.  ]\n",
      " [ 318.75  247.5   442.5   388.75   24.  ]\n",
      " [ 397.5   242.5   571.25  395.     24.  ]]\n",
      "total_anchors 16650\n",
      "inds_inside 5944\n",
      "anchors.shape (5944, 4)\n",
      "cfg.TRAIN.RPN_FG_FRACTION , cfg.TRAIN.RPN_BATCHSIZE 0.75 512\n",
      "was 5376 inds, disabling 4877, now 499 inds\n",
      "means:\n",
      "[[-0.03129098 -0.0081403  -0.01392334  0.11795976]]\n",
      "stdevs:\n",
      "[[ 0.1062621   0.05485952  0.3766335   0.0689785 ]]\n",
      "---------------\n",
      "(5944,)\n",
      "(16650,)\n",
      "---------------\n",
      "rpn: max max_overlap 0.833974240567\n",
      "rpn: num_positive 13\n",
      "rpn: num_negative 499\n",
      "rpn: num_positive avg 13\n",
      "rpn: num_negative avg 499\n",
      "rpn_loss_box Variable containing:\n",
      " 187.6431\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "rpn_cross_entropy Variable containing:\n",
      " 6.1223\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "Variable containing:\n",
      " 6.1223\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 187.6431\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "loss Variable containing:\n",
      " 193.7655\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "step 4, image: COCO_train2014_000000309241.jpg, loss: 216.5711\n",
      "[[ 2.00393748  2.15689492  4.3484478   6.18839788]\n",
      " [-2.41212606 -5.67282343 -2.17623591  3.80372286]\n",
      " [ 1.85599148 -0.18943962  1.11155391  2.29392934]\n",
      " ..., \n",
      " [ 0.169236    4.69155502  1.41259754  3.69683695]\n",
      " [-0.18437907 -0.57744801 -0.43970016  1.45623112]\n",
      " [-4.66620493 -1.03290105  2.83920908  2.11609983]]\n",
      "rpn_cls_score.shape (1, 18, 37, 50)\n",
      "image info [[ 600.    800.      1.25]]\n",
      "anchors:\n",
      "[[ -84.  -40.   99.   55.]\n",
      " [-176.  -88.  191.  103.]\n",
      " [-360. -184.  375.  199.]\n",
      " [ -56.  -56.   71.   71.]\n",
      " [-120. -120.  135.  135.]\n",
      " [-248. -248.  263.  263.]\n",
      " [ -36.  -80.   51.   95.]\n",
      " [ -80. -168.   95.  183.]\n",
      " [-168. -344.  183.  359.]]\n",
      "anchor shapes:\n",
      "[[ 183.   95.]\n",
      " [ 367.  191.]\n",
      " [ 735.  383.]\n",
      " [ 127.  127.]\n",
      " [ 255.  255.]\n",
      " [ 511.  511.]\n",
      " [  87.  175.]\n",
      " [ 175.  351.]\n",
      " [ 351.  703.]]\n",
      "AnchorTargetLayer: height 37 width 50\n",
      "\n",
      "im_size: (600.0, 800.0)\n",
      "scale: 1.25\n",
      "height, width: (37, 50)\n",
      "rpn: gt_boxes.shape (3, 5)\n",
      "rpn: gt_boxes [[ 140.    253.75  185.    430.     24.  ]\n",
      " [ 318.75  247.5   442.5   388.75   24.  ]\n",
      " [ 397.5   242.5   571.25  395.     24.  ]]\n",
      "total_anchors 16650\n",
      "inds_inside 5944\n",
      "anchors.shape (5944, 4)\n",
      "cfg.TRAIN.RPN_FG_FRACTION , cfg.TRAIN.RPN_BATCHSIZE 0.75 512\n",
      "was 5376 inds, disabling 4877, now 499 inds\n",
      "means:\n",
      "[[-0.03129098 -0.0081403  -0.01392334  0.11795976]]\n",
      "stdevs:\n",
      "[[ 0.1062621   0.05485952  0.3766335   0.0689785 ]]\n",
      "---------------\n",
      "(5944,)\n",
      "(16650,)\n",
      "---------------\n",
      "rpn: max max_overlap 0.833974240567\n",
      "rpn: num_positive 13\n",
      "rpn: num_negative 499\n",
      "rpn: num_positive avg 13\n",
      "rpn: num_negative avg 499\n",
      "rpn_loss_box Variable containing:\n",
      " 166.7821\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "rpn_cross_entropy Variable containing:\n",
      " 6.5844\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "Variable containing:\n",
      " 6.5844\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 166.7821\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "loss Variable containing:\n",
      " 173.3664\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5, image: COCO_train2014_000000309241.jpg, loss: 207.9302\n",
      "[[ 2.01664066  2.14559746  4.32283592  6.16395473]\n",
      " [-2.40709615 -5.65244865 -2.16751719  3.79762363]\n",
      " [ 1.88160038 -0.21351023  1.09861791  2.31298995]\n",
      " ..., \n",
      " [ 0.13408156  4.71459627  1.39773202  3.66902113]\n",
      " [-0.14807826 -0.56031293 -0.45720699  1.44443738]\n",
      " [-4.67316961 -1.05764604  2.82506323  2.15405273]]\n",
      "rpn_cls_score.shape (1, 18, 37, 50)\n",
      "image info [[ 600.    800.      1.25]]\n",
      "anchors:\n",
      "[[ -84.  -40.   99.   55.]\n",
      " [-176.  -88.  191.  103.]\n",
      " [-360. -184.  375.  199.]\n",
      " [ -56.  -56.   71.   71.]\n",
      " [-120. -120.  135.  135.]\n",
      " [-248. -248.  263.  263.]\n",
      " [ -36.  -80.   51.   95.]\n",
      " [ -80. -168.   95.  183.]\n",
      " [-168. -344.  183.  359.]]\n",
      "anchor shapes:\n",
      "[[ 183.   95.]\n",
      " [ 367.  191.]\n",
      " [ 735.  383.]\n",
      " [ 127.  127.]\n",
      " [ 255.  255.]\n",
      " [ 511.  511.]\n",
      " [  87.  175.]\n",
      " [ 175.  351.]\n",
      " [ 351.  703.]]\n",
      "AnchorTargetLayer: height 37 width 50\n",
      "\n",
      "im_size: (600.0, 800.0)\n",
      "scale: 1.25\n",
      "height, width: (37, 50)\n",
      "rpn: gt_boxes.shape (3, 5)\n",
      "rpn: gt_boxes [[ 140.    253.75  185.    430.     24.  ]\n",
      " [ 318.75  247.5   442.5   388.75   24.  ]\n",
      " [ 397.5   242.5   571.25  395.     24.  ]]\n",
      "total_anchors 16650\n",
      "inds_inside 5944\n",
      "anchors.shape (5944, 4)\n",
      "cfg.TRAIN.RPN_FG_FRACTION , cfg.TRAIN.RPN_BATCHSIZE 0.75 512\n",
      "was 5376 inds, disabling 4877, now 499 inds\n",
      "means:\n",
      "[[-0.03129098 -0.0081403  -0.01392334  0.11795976]]\n",
      "stdevs:\n",
      "[[ 0.1062621   0.05485952  0.3766335   0.0689785 ]]\n",
      "---------------\n",
      "(5944,)\n",
      "(16650,)\n",
      "---------------\n",
      "rpn: max max_overlap 0.833974240567\n",
      "rpn: num_positive 13\n",
      "rpn: num_negative 499\n",
      "rpn: num_positive avg 13\n",
      "rpn: num_negative avg 499\n",
      "rpn_loss_box Variable containing:\n",
      " 145.5831\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "rpn_cross_entropy Variable containing:\n",
      " 7.3482\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "Variable containing:\n",
      " 7.3482\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 145.5831\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "loss Variable containing:\n",
      " 152.9314\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "step 6, image: COCO_train2014_000000309241.jpg, loss: 198.7637\n",
      "[[ 2.03392577  2.13313198  4.29336643  6.13456345]\n",
      " [-2.39970732 -5.6406908  -2.16915727  3.79620957]\n",
      " [ 1.90851617 -0.24138871  1.07150626  2.33570504]\n",
      " ..., \n",
      " [ 0.09392643  4.73673964  1.38126397  3.64070511]\n",
      " [-0.10582989 -0.54964733 -0.4785009   1.43300879]\n",
      " [-4.68312263 -1.08479202  2.80837226  2.19673824]]\n",
      "rpn_cls_score.shape (1, 18, 37, 50)\n",
      "image info [[ 600.    800.      1.25]]\n",
      "anchors:\n",
      "[[ -84.  -40.   99.   55.]\n",
      " [-176.  -88.  191.  103.]\n",
      " [-360. -184.  375.  199.]\n",
      " [ -56.  -56.   71.   71.]\n",
      " [-120. -120.  135.  135.]\n",
      " [-248. -248.  263.  263.]\n",
      " [ -36.  -80.   51.   95.]\n",
      " [ -80. -168.   95.  183.]\n",
      " [-168. -344.  183.  359.]]\n",
      "anchor shapes:\n",
      "[[ 183.   95.]\n",
      " [ 367.  191.]\n",
      " [ 735.  383.]\n",
      " [ 127.  127.]\n",
      " [ 255.  255.]\n",
      " [ 511.  511.]\n",
      " [  87.  175.]\n",
      " [ 175.  351.]\n",
      " [ 351.  703.]]\n",
      "AnchorTargetLayer: height 37 width 50\n",
      "\n",
      "im_size: (600.0, 800.0)\n",
      "scale: 1.25\n",
      "height, width: (37, 50)\n",
      "rpn: gt_boxes.shape (3, 5)\n",
      "rpn: gt_boxes [[ 140.    253.75  185.    430.     24.  ]\n",
      " [ 318.75  247.5   442.5   388.75   24.  ]\n",
      " [ 397.5   242.5   571.25  395.     24.  ]]\n",
      "total_anchors 16650\n",
      "inds_inside 5944\n",
      "anchors.shape (5944, 4)\n",
      "cfg.TRAIN.RPN_FG_FRACTION , cfg.TRAIN.RPN_BATCHSIZE 0.75 512\n",
      "was 5376 inds, disabling 4877, now 499 inds\n",
      "means:\n",
      "[[-0.03129098 -0.0081403  -0.01392334  0.11795976]]\n",
      "stdevs:\n",
      "[[ 0.1062621   0.05485952  0.3766335   0.0689785 ]]\n",
      "---------------\n",
      "(5944,)\n",
      "(16650,)\n",
      "---------------\n",
      "rpn: max max_overlap 0.833974240567\n",
      "rpn: num_positive 13\n",
      "rpn: num_negative 499\n",
      "rpn: num_positive avg 13\n",
      "rpn: num_negative avg 499\n",
      "rpn_loss_box Variable containing:\n",
      " 123.8271\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "rpn_cross_entropy Variable containing:\n",
      " 6.3380\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "Variable containing:\n",
      " 6.3380\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 123.8271\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "loss Variable containing:\n",
      " 130.1651\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "step 7, image: COCO_train2014_000000309241.jpg, loss: 188.9639\n",
      "[[ 2.05481529  2.12240696  4.26176929  6.1036253 ]\n",
      " [-2.38947058 -5.63600159 -2.17754316  3.80088615]\n",
      " [ 1.9417932  -0.27361256  1.0344758   2.35775471]\n",
      " ..., \n",
      " [ 0.05415599  4.7547636   1.36373794  3.60854125]\n",
      " [-0.06281926 -0.54352039 -0.49350929  1.4211663 ]\n",
      " [-4.68867636 -1.11167347  2.79537439  2.24088717]]\n",
      "rpn_cls_score.shape (1, 18, 37, 50)\n",
      "image info [[ 600.    800.      1.25]]\n",
      "anchors:\n",
      "[[ -84.  -40.   99.   55.]\n",
      " [-176.  -88.  191.  103.]\n",
      " [-360. -184.  375.  199.]\n",
      " [ -56.  -56.   71.   71.]\n",
      " [-120. -120.  135.  135.]\n",
      " [-248. -248.  263.  263.]\n",
      " [ -36.  -80.   51.   95.]\n",
      " [ -80. -168.   95.  183.]\n",
      " [-168. -344.  183.  359.]]\n",
      "anchor shapes:\n",
      "[[ 183.   95.]\n",
      " [ 367.  191.]\n",
      " [ 735.  383.]\n",
      " [ 127.  127.]\n",
      " [ 255.  255.]\n",
      " [ 511.  511.]\n",
      " [  87.  175.]\n",
      " [ 175.  351.]\n",
      " [ 351.  703.]]\n",
      "AnchorTargetLayer: height 37 width 50\n",
      "\n",
      "im_size: (600.0, 800.0)\n",
      "scale: 1.25\n",
      "height, width: (37, 50)\n",
      "rpn: gt_boxes.shape (3, 5)\n",
      "rpn: gt_boxes [[ 140.    253.75  185.    430.     24.  ]\n",
      " [ 318.75  247.5   442.5   388.75   24.  ]\n",
      " [ 397.5   242.5   571.25  395.     24.  ]]\n",
      "total_anchors 16650\n",
      "inds_inside 5944\n",
      "anchors.shape (5944, 4)\n",
      "cfg.TRAIN.RPN_FG_FRACTION , cfg.TRAIN.RPN_BATCHSIZE 0.75 512\n",
      "was 5376 inds, disabling 4877, now 499 inds\n",
      "means:\n",
      "[[-0.03129098 -0.0081403  -0.01392334  0.11795976]]\n",
      "stdevs:\n",
      "[[ 0.1062621   0.05485952  0.3766335   0.0689785 ]]\n",
      "---------------\n",
      "(5944,)\n",
      "(16650,)\n",
      "---------------\n",
      "rpn: max max_overlap 0.833974240567\n",
      "rpn: num_positive 13\n",
      "rpn: num_negative 499\n",
      "rpn: num_positive avg 13\n",
      "rpn: num_negative avg 499\n",
      "rpn_loss_box Variable containing:\n",
      " 102.0698\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "rpn_cross_entropy Variable containing:\n",
      " 6.7232\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "Variable containing:\n",
      " 6.7232\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 102.0698\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "loss Variable containing:\n",
      " 108.7930\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "step 8, image: COCO_train2014_000000309241.jpg, loss: 178.9425\n",
      "[[ 2.08238602  2.11627507  4.23656893  6.07218599]\n",
      " [-2.36953092 -5.64920998 -2.18838239  3.8271656 ]\n",
      " [ 1.96712506 -0.3062849   0.99378437  2.36812663]\n",
      " ..., \n",
      " [ 0.02391323  4.76702166  1.34413874  3.57670355]\n",
      " [-0.02736312 -0.54346061 -0.50789994  1.41273987]\n",
      " [-4.69669437 -1.13666701  2.78085279  2.27892232]]\n",
      "rpn_cls_score.shape (1, 18, 37, 50)\n",
      "image info [[ 600.    800.      1.25]]\n",
      "anchors:\n",
      "[[ -84.  -40.   99.   55.]\n",
      " [-176.  -88.  191.  103.]\n",
      " [-360. -184.  375.  199.]\n",
      " [ -56.  -56.   71.   71.]\n",
      " [-120. -120.  135.  135.]\n",
      " [-248. -248.  263.  263.]\n",
      " [ -36.  -80.   51.   95.]\n",
      " [ -80. -168.   95.  183.]\n",
      " [-168. -344.  183.  359.]]\n",
      "anchor shapes:\n",
      "[[ 183.   95.]\n",
      " [ 367.  191.]\n",
      " [ 735.  383.]\n",
      " [ 127.  127.]\n",
      " [ 255.  255.]\n",
      " [ 511.  511.]\n",
      " [  87.  175.]\n",
      " [ 175.  351.]\n",
      " [ 351.  703.]]\n",
      "AnchorTargetLayer: height 37 width 50\n",
      "\n",
      "im_size: (600.0, 800.0)\n",
      "scale: 1.25\n",
      "height, width: (37, 50)\n",
      "rpn: gt_boxes.shape (3, 5)\n",
      "rpn: gt_boxes [[ 140.    253.75  185.    430.     24.  ]\n",
      " [ 318.75  247.5   442.5   388.75   24.  ]\n",
      " [ 397.5   242.5   571.25  395.     24.  ]]\n",
      "total_anchors 16650\n",
      "inds_inside 5944\n",
      "anchors.shape (5944, 4)\n",
      "cfg.TRAIN.RPN_FG_FRACTION , cfg.TRAIN.RPN_BATCHSIZE 0.75 512\n",
      "was 5376 inds, disabling 4877, now 499 inds\n",
      "means:\n",
      "[[-0.03129098 -0.0081403  -0.01392334  0.11795976]]\n",
      "stdevs:\n",
      "[[ 0.1062621   0.05485952  0.3766335   0.0689785 ]]\n",
      "---------------\n",
      "(5944,)\n",
      "(16650,)\n",
      "---------------\n",
      "rpn: max max_overlap 0.833974240567\n",
      "rpn: num_positive 13\n",
      "rpn: num_negative 499\n",
      "rpn: num_positive avg 13\n",
      "rpn: num_negative avg 499\n",
      "rpn_loss_box Variable containing:\n",
      " 83.9372\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "rpn_cross_entropy Variable containing:\n",
      " 7.1999\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "Variable containing:\n",
      " 7.1999\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Variable containing:\n",
      " 83.9372\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "--\n",
      "loss Variable containing:\n",
      " 91.1371\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "step 9, image: COCO_train2014_000000309241.jpg, loss: 169.1864\n"
     ]
    }
   ],
   "source": [
    "train(t, optimizer, net, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'rpn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('./rpn.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs =  cap[13499]\n",
    "im_data = blobs['data']\n",
    "im_info = blobs['im_info']\n",
    "gt_boxes = np.hstack([ blobs['boxes'] , blobs['gt_classes'][:, np.newaxis]])\n",
    "gt_ishard = blobs['gt_ishard']\n",
    "dontcare_areas = blobs['dontcare_areas']\n",
    "\n",
    "print blobs['boxes'] / im_info[0][2]\n",
    "print blobs['image_info']\n",
    "print im_data.shape\n",
    "origin_gt_box =  blobs['boxes'] / im_info[0][2]\n",
    "print origin_gt_box\n",
    "print gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load('./rpn.pkl'))\n",
    "\n",
    "net.eval()\n",
    "_, result = net(im_data, im_info, gt_boxes, gt_ishard, dontcare_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_data =  result.data.cpu().numpy()\n",
    "features =  _.data.cpu().numpy()\n",
    "print features.shape\n",
    "print box_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "base_path = './data/mscoco/images/train2014/'\n",
    "img_path = os.path.join(base_path, blobs['im_name'])\n",
    "# Display the image\n",
    "im_data = cv2.imread(img_path)\n",
    "\n",
    "ax.imshow(im_data)\n",
    "# Create a Rectangle patch\n",
    "for i, box in enumerate(box_data):\n",
    "    box = box[1:]\n",
    "    rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1] ,linewidth=1,edgecolor='b',facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "for i, box in enumerate(origin_gt_box):\n",
    "    rect = patches.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1]  ,linewidth=1,edgecolor='r',facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "# debug max overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
