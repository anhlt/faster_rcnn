{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "from scipy.misc import imread\n",
    "import matplotlib.patches as patches\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import torch\n",
    "from torch.autograd import  Variable\n",
    "from faster_rcnn.utils.images import imshow\n",
    "from faster_rcnn.utils.cython_bbox import bbox_overlaps\n",
    "\n",
    "from faster_rcnn.fastrcnn.bbox_transform import bbox_transform, bbox_transform_inv\n",
    "import cPickle\n",
    "from faster_rcnn.rpn_msr.proposal_target_layer_2 import  ProposalTargetLayer\n",
    "from torch.optim import SGD, RMSprop, Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from faster_rcnn.roi_pooling.modules.roi_pool import RoIPool\n",
    "import gc\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sorted_index', 'rb') as fp:\n",
    "    sorted_index = cPickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc dữ liệu từ MS COCO dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.97s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from faster_rcnn.utils.datasets.mscoco.dataset import CocoData\n",
    "from faster_rcnn.utils.datasets.data_generator import CocoGenerator\n",
    "from faster_rcnn.utils.datasets.data_generator import Enqueuer\n",
    "\n",
    "dataDir = './data/mscoco'\n",
    "dataType = 'train2014'\n",
    "annFile='%s/annotations/instances_%s.json'%(dataDir,dataType)\n",
    "pre_proposal_folder = './data/mscoco/coco_proposals/MCG/'\n",
    "batch_size = 2\n",
    "\n",
    "images_dir = os.path.join(dataDir,'images', dataType)\n",
    "cap = CocoData(root = images_dir, annFile = annFile)\n",
    "\n",
    "data_gen = CocoGenerator(data=cap, sorted_index=sorted_index, batch_size=batch_size)\n",
    "queue = Enqueuer(generator=data_gen)\n",
    "queue.start(max_queue_size=10, workers=2)\n",
    "t = queue.get()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thử hiển thị ảnh cùng các bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from faster_rcnn.faster_rcnn_2 import RPN, FastRCNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tính toán feed-forward\n",
    "\n",
    "\n",
    "Chúng ta sử dụng một ảnh có kích thước đầu vào là  `(width , height) = (600, 800)`\n",
    "\n",
    "Input:\n",
    "    - im_data : \n",
    "        kích thước : (batch_size, dim, witdh, height)\n",
    "    - ground_boxes: \n",
    "        kích thước (n, 4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['__background__'] + [x['name'] for x in cap.coco.loadCats(cap.coco.getCatIds())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_target_layer = ProposalTargetLayer(len(categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "faster_rcnn/network.py:26: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  nn.init.xavier_normal(self.conv.weight)\n",
      "faster_rcnn/network.py:54: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  nn.init.xavier_normal(self.fc.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FastRCNN(\n",
       "  (rpn): RPN(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace)\n",
       "    )\n",
       "    (conv1): Conv2d(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (score_conv): Conv2d(\n",
       "      (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (bbox_conv): Conv2d(\n",
       "      (conv): Conv2d(512, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (anchor_target_layer): AnchorTargerLayer()\n",
       "    (proposal_layer): ProposalLayer()\n",
       "  )\n",
       "  (proposal_target_layer): ProposalTargetLayer()\n",
       "  (roi_pool): RoIPool()\n",
       "  (fc6): FC(\n",
       "    (fc): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (relu): ReLU(inplace)\n",
       "  )\n",
       "  (fc7): FC(\n",
       "    (fc): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (relu): ReLU(inplace)\n",
       "  )\n",
       "  (score_fc): FC(\n",
       "    (fc): Linear(in_features=4096, out_features=81, bias=True)\n",
       "  )\n",
       "  (bbox_fc): FC(\n",
       "    (fc): Linear(in_features=4096, out_features=324, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FastRCNN(categories, debug=False)\n",
    "net.cuda()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train(None, optimizer, exp_lr_scheduler, net.rpn, 1, 300)\n",
    "# torch.save(net.rpn.state_dict(), 'rpn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = filter(lambda x: x.requires_grad, net.parameters())\n",
    "optimizer = SGD(param, lr=1e-4, momentum=0.9, weight_decay=0.0005)\n",
    "exp_lr_scheduler = StepLR(optimizer, step_size=1000, gamma=0.95)\n",
    "save_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_gen, optimizer, lr_scheduler ,model, epochs, steps_per_epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    cross_entropy = 0\n",
    "    loss_box = 0\n",
    "    rpn_loss = 0\n",
    "\n",
    "    for step in range(1, steps_per_epoch +1):\n",
    "        lr_scheduler.step()\n",
    "        blobs = data_gen.next()\n",
    "        \n",
    "        max_height = np.max([blob['tensor'].shape[2] for blob in blobs])\n",
    "        max_width = np.max([blob['tensor'].shape[3] for blob in blobs])\n",
    "        batch_tensor = torch.Tensor(batch_size, 3, max_height, max_width).fill_(0.)\n",
    "        total_boxes = 0\n",
    "        batch_boxes = np.empty((0, 5))\n",
    "        batch_boxes_index = np.empty((0,), dtype=np.int)\n",
    "        im_info = np.array([[batch_tensor.shape[2], batch_tensor.shape[3]]])\n",
    "        for i, blob in enumerate(blobs):\n",
    "            total_boxes = blob['boxes'].shape[0]\n",
    "            gt_classes =  blob['gt_classes']\n",
    "            gt_boxes = np.hstack([blob['boxes'] , gt_classes[:, np.newaxis]])\n",
    "            batch_boxes = np.vstack((batch_boxes, gt_boxes))\n",
    "            a =  np.zeros((total_boxes , ), dtype=np.int)\n",
    "            a.fill(i)\n",
    "            batch_boxes_index = np.concatenate((batch_boxes_index, a), axis=0)\n",
    "\n",
    "        im_info = np.array([[batch_tensor.shape[2], batch_tensor.shape[3]]])\n",
    "        try:\n",
    "            cls_prob, bbox_pred, rois = model(batch_tensor, im_info, batch_boxes, batch_boxes_index)\n",
    "        except Exception as e:\n",
    "            print batch_boxes_index\n",
    "            continue\n",
    "\n",
    "\n",
    "        cls_data = cls_prob.data.cpu().numpy()\n",
    "        max_class_idx = np.argmax(cls_data, axis=1)\n",
    "        loss = model.loss\n",
    "        cross_entropy += model.cross_entropy.item()\n",
    "        loss_box += model.loss_box.item()\n",
    "        train_loss += loss.item()\n",
    "        rpn_loss += model.rpn.loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            log_text = 'step %d,  loss: %.4f' % (\n",
    "                step, train_loss /(step))\n",
    "            print(log_text)\n",
    "\n",
    "            re_cnt = True\n",
    "\n",
    "\n",
    "        if step % save_interval == 0:\n",
    "            torch.save(model.state_dict(), 'faster_model_at_step_%s.pkl' % step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64, 3, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64, 64, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([64]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 64, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1802, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1828, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1829, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1929, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 2000, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1699, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1754, 600]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([128]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256, 128, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256, 256, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256, 256, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([256]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 256, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1548, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1762, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1648, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1666, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1613, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1613, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1587, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1606, 600]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512, 512, 3, 3]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([512]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([24, 512, 1, 1]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([24]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([48, 512, 1, 1]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([48]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1542, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1517, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1536, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1500, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1505, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1454, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1, 3, 1454, 600]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1]))\n",
      "(<class 'torch.Tensor'>, torch.Size([1]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4096, 25088]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4096, 4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([81, 4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([81]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([324, 4096]))\n",
      "(<class 'torch.nn.parameter.Parameter'>, torch.Size([324]))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "for obj in gc.get_objects():\n",
    "    if torch.is_tensor(obj) and torch.is_tensor(obj.data):\n",
    "        print(type(obj), obj.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "faster_rcnn/faster_rcnn_2.py:168: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  cls_prob = F.softmax(cls_score)\n",
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10,  loss: 7.6980\n",
      "[0]\n",
      "step 20,  loss: 7.1992\n",
      "step 30,  loss: 6.8135\n",
      "step 40,  loss: 6.5731\n",
      "step 50,  loss: 6.4120\n",
      "step 60,  loss: 6.2265\n",
      "step 70,  loss: 6.1076\n",
      "step 80,  loss: 5.9470\n",
      "step 90,  loss: 5.8382\n",
      "step 100,  loss: 5.7147\n",
      "step 110,  loss: 5.6187\n",
      "step 120,  loss: 5.5275\n",
      "step 130,  loss: 5.5067\n",
      "step 140,  loss: 5.4674\n",
      "step 150,  loss: 5.4290\n",
      "step 160,  loss: 5.4123\n",
      "step 170,  loss: 5.3635\n",
      "step 180,  loss: 5.3186\n",
      "step 190,  loss: 5.2600\n",
      "step 200,  loss: 5.2152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 210,  loss: 5.1615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n",
      "step 220,  loss: 5.0721\n",
      "[0 0 0 0 0 0 0 0 0]\n",
      "step 230,  loss: 4.9926\n",
      "step 240,  loss: 4.9310\n",
      "step 250,  loss: 4.9158\n",
      "step 260,  loss: 4.8582\n",
      "step 270,  loss: 4.8718\n",
      "step 280,  loss: 4.8768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 290,  loss: 4.8533\n",
      "[0 0 0 0]\n",
      "step 300,  loss: 4.8126\n",
      "step 310,  loss: 4.7819\n",
      "step 320,  loss: 4.7714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 330,  loss: 4.7524\n",
      "[0 0]\n",
      "step 340,  loss: 4.7059\n",
      "step 350,  loss: 4.6869\n",
      "step 360,  loss: 4.6568\n",
      "step 370,  loss: 4.6161\n",
      "step 380,  loss: 4.5873\n",
      "step 390,  loss: 4.5600\n",
      "step 400,  loss: 4.5491\n",
      "step 410,  loss: 4.5329\n",
      "step 420,  loss: 4.5125\n",
      "step 430,  loss: 4.4973\n",
      "step 440,  loss: 4.4857\n",
      "step 450,  loss: 4.4695\n",
      "step 460,  loss: 4.4616\n",
      "step 470,  loss: 4.4450\n",
      "step 480,  loss: 4.4249\n",
      "step 490,  loss: 4.4267\n",
      "step 500,  loss: 4.4078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 510,  loss: 4.3911\n",
      "[0 0 0 0 0 0 0]\n",
      "step 520,  loss: 4.3740\n",
      "step 530,  loss: 4.3514\n",
      "step 540,  loss: 4.3351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 550,  loss: 4.3254\n",
      "[0 0]\n",
      "step 560,  loss: 4.3079\n",
      "step 570,  loss: 4.3041\n",
      "step 580,  loss: 4.2935\n",
      "step 590,  loss: 4.2877\n",
      "step 600,  loss: 4.2744\n",
      "step 610,  loss: 4.2721\n",
      "step 620,  loss: 4.2578\n",
      "step 630,  loss: 4.2474\n",
      "step 640,  loss: 4.2410\n",
      "step 650,  loss: 4.2499\n",
      "step 660,  loss: 4.2410\n",
      "step 670,  loss: 4.2391\n",
      "step 680,  loss: 4.2309\n",
      "step 690,  loss: 4.2251\n",
      "step 700,  loss: 4.2070\n",
      "step 710,  loss: 4.1953\n",
      "step 720,  loss: 4.1924\n",
      "step 730,  loss: 4.1918\n",
      "step 740,  loss: 4.1801\n",
      "step 750,  loss: 4.1791\n",
      "step 760,  loss: 4.1736\n",
      "step 770,  loss: 4.1706\n",
      "step 780,  loss: 4.1614\n",
      "step 790,  loss: 4.1533\n",
      "step 800,  loss: 4.1385\n",
      "step 810,  loss: 4.1358\n",
      "step 820,  loss: 4.1282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 830,  loss: 4.1172\n",
      "[0 0 0 0 0]\n",
      "step 840,  loss: 4.1099\n",
      "step 850,  loss: 4.0967\n",
      "step 860,  loss: 4.0872\n",
      "step 870,  loss: 4.0960\n",
      "step 880,  loss: 4.1050\n",
      "step 890,  loss: 4.0985\n",
      "step 900,  loss: 4.0953\n",
      "step 910,  loss: 4.0867\n",
      "step 920,  loss: 4.0879\n",
      "step 930,  loss: 4.0860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 940,  loss: 4.0815\n",
      "[0 0 0 0 0 0 0]\n",
      "step 950,  loss: 4.0793\n",
      "step 960,  loss: 4.0769\n",
      "step 970,  loss: 4.0796\n",
      "step 980,  loss: 4.0700\n",
      "step 990,  loss: 4.0659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000,  loss: 4.0690\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "step 1010,  loss: 4.0599\n",
      "step 1020,  loss: 4.0568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1030,  loss: 4.0506\n",
      "step 1040,  loss: 4.0474\n",
      "[0 0]\n",
      "step 1050,  loss: 4.0446\n",
      "step 1060,  loss: 4.0421\n",
      "step 1070,  loss: 4.0400\n",
      "step 1080,  loss: 4.0306\n",
      "step 1090,  loss: 4.0284\n",
      "step 1100,  loss: 4.0265\n",
      "step 1110,  loss: 4.0207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1120,  loss: 4.0124\n",
      "[0]\n",
      "step 1130,  loss: 4.0078\n",
      "step 1140,  loss: 4.0046\n",
      "step 1150,  loss: 4.0001\n",
      "step 1160,  loss: 3.9928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1170,  loss: 3.9852\n",
      "[0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:faster_rcnn.utils.datasets.mscoco.dataset:need more than 0 values to unpack\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1180,  loss: 3.9784\n",
      "[0 0]\n",
      "step 1190,  loss: 3.9721\n",
      "step 1200,  loss: 3.9670\n",
      "step 1210,  loss: 3.9589\n",
      "step 1220,  loss: 3.9554\n",
      "step 1230,  loss: 3.9538\n",
      "step 1240,  loss: 3.9540\n"
     ]
    }
   ],
   "source": [
    "train(t, optimizer=optimizer,lr_scheduler=exp_lr_scheduler, model=net, epochs=1, steps_per_epoch=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
