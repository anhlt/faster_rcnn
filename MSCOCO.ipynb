{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from faster_rcnn.utils.cython_bbox import bbox_overlaps\n",
    "from pycrayon import CrayonClient\n",
    "\n",
    "import cPickle\n",
    "from torch.optim import SGD, RMSprop, Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from datetime import datetime\n",
    "from faster_rcnn.utils.datasets.adapter import convert_data\n",
    "from faster_rcnn.utils.evaluate.metter import AverageMeter\n",
    "from faster_rcnn.utils.display.images import imshow, result_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sorted_index', 'rb') as fp:\n",
    "    sorted_index = cPickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc dữ liệu từ MS COCO dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_rcnn.utils.datasets.adapter import convert_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=14.40s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from faster_rcnn.utils.datasets.mscoco.dataset import CocoData\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "dataDir = './data/mscoco'\n",
    "dataType = 'train2014'\n",
    "annFile='%s/annotations/instances_%s.json'%(dataDir,dataType)\n",
    "batch_size = 4\n",
    "\n",
    "images_dir = os.path.join(dataDir,'images', dataType)\n",
    "cap = CocoData(root = images_dir, annFile = annFile,sorted_indexes=sorted_index)\n",
    "\n",
    "train_data_loader = DataLoader(cap, batch_size=batch_size, shuffle=False, collate_fn=convert_data, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20696\n"
     ]
    }
   ],
   "source": [
    "train_data_loader.batch_size\n",
    "print len(train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thử hiển thị ảnh cùng các bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from faster_rcnn.faster_rcnn import FastRCNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tính toán feed-forward\n",
    "\n",
    "\n",
    "Chúng ta sử dụng một ảnh có kích thước đầu vào là  `(width , height) = (600, 800)`\n",
    "\n",
    "Input:\n",
    "    - im_data : \n",
    "        kích thước : (batch_size, dim, witdh, height)\n",
    "    - ground_boxes: \n",
    "        kích thước (n, 4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['__background__'] + [x['name'] for x in cap.coco.loadCats(cap.coco.getCatIds())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python2.7/site-packages/torch/nn/parallel/data_parallel.py:24: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FastRCNN(\n",
       "  (rpn): RPN(\n",
       "    (features): DataParallel(\n",
       "      (module): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU(inplace)\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): ReLU(inplace)\n",
       "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (8): ReLU(inplace)\n",
       "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (11): ReLU(inplace)\n",
       "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (13): ReLU(inplace)\n",
       "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (15): ReLU(inplace)\n",
       "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (18): ReLU(inplace)\n",
       "        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (20): ReLU(inplace)\n",
       "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (22): ReLU(inplace)\n",
       "        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (25): ReLU(inplace)\n",
       "        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (27): ReLU(inplace)\n",
       "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (29): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (conv1): DataParallel(\n",
       "      (module): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (score_conv): DataParallel(\n",
       "      (module): Conv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (bbox_conv): DataParallel(\n",
       "      (module): Conv2d(\n",
       "        (conv): Conv2d(512, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (anchor_target_layer): AnchorTargerLayer()\n",
       "    (proposal_layer): ProposalLayer()\n",
       "  )\n",
       "  (proposal_target_layer): ProposalTargetLayer()\n",
       "  (roi_pool): RoIPool()\n",
       "  (fc6): DataParallel(\n",
       "    (module): FC(\n",
       "      (fc): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (fc7): DataParallel(\n",
       "    (module): FC(\n",
       "      (fc): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (score_fc): DataParallel(\n",
       "    (module): FC(\n",
       "      (fc): Linear(in_features=4096, out_features=81, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (bbox_fc): DataParallel(\n",
       "    (module): FC(\n",
       "      (fc): Linear(in_features=4096, out_features=324, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FastRCNN(categories, debug=False)\n",
    "net.cuda()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = filter(lambda x: x.requires_grad, net.parameters())\n",
    "optimizer = SGD(param, lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
    "exp_lr_scheduler = StepLR(optimizer, step_size=1000, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"faster_rcnn.utils.datasets.mscoco.dataset\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.6985, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3918, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(5.5202, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(0.6927, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5302, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(5.4387, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2124, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(0.6938, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6935, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(5.4229, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2228, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(0.6949, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3631, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(5.4094, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.1438, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(0.6932, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3326, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(5.9758, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2526, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(0.6985, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2796, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(5.4364, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.1901, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(0.6987, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2602, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(5.7984, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.1241, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(0.6926, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(5.6817, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3547, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(0.6983, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2599, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(5.0327, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3822, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(0.6950, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.4230, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(5.1525, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3705, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(0.7018, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3654, device='cuda:0', grad_fn=<MeanBackward1>))\n",
      "(tensor(5.8302, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5541, device='cuda:0', grad_fn=<MeanBackward1>))\n"
     ]
    }
   ],
   "source": [
    "for i, blobs in enumerate(train_data_loader):\n",
    "    if i > 10:\n",
    "        break\n",
    "    batch_tensor, im_info, batch_boxes, batch_boxes_index = blobs\n",
    "    cls_prob, bbox_pred, rois, cls_score, target, rpn_cls_prob_reshape, rpn_bbox_pred, rpn_target = net(batch_tensor, im_info, batch_boxes, batch_boxes_index)\n",
    "    rpn_cross_entropy, rpn_bbox_loss = net.rpn.build_loss(rpn_cls_prob_reshape, rpn_bbox_pred, rpn_target)\n",
    "    cross_entropy, bbox_loss = net.build_loss(cls_score, bbox_pred, target)\n",
    "    print(rpn_cross_entropy, rpn_bbox_loss)\n",
    "    print(cross_entropy, bbox_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_gen ,model, tensorboard_client, metters, optimizer, lr_scheduler, current_epoch=0):\n",
    "    \n",
    "    steps_per_epoch = len(train_data_loader) \n",
    "    model.train()\n",
    "    train_loss , cross_entropy , loss_box, rpn_loss = metters\n",
    "    for step, blobs in enumerate(train_data_loader):\n",
    "        if step < 20670:\n",
    "            if step % 100 == 1:\n",
    "                print(step, datetime.now().strftime('%m/%d_%H:%M'))\n",
    "            continue\n",
    "        batch_tensor, im_info, batch_boxes, batch_boxes_index = blobs\n",
    "        print batch_tensor.shape\n",
    "        optimizer.zero_grad()\n",
    "        model(batch_tensor, im_info, batch_boxes, batch_boxes_index)\n",
    "        cross_entropy.update(model.cross_entropy.item())\n",
    "        loss_box.update(model.loss_box.item())\n",
    "        train_loss.update(model.loss.item())\n",
    "        rpn_loss.update(model.rpn.loss.item())\n",
    "        loss = model.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()        \n",
    "\n",
    "\n",
    "        current_step = current_epoch * steps_per_epoch + step\n",
    "        if step % 30 == 1:\n",
    "            log_text = 'epoch: %d : step %d,  loss: %.4f at %s' % (\n",
    "                current_epoch + 1, step , train_loss.avg, datetime.now().strftime('%m/%d_%H:%M'))\n",
    "            print(log_text)\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            tensorboard_client.add_scalar_value('train_loss', train_loss.avg, step=current_step)\n",
    "            tensorboard_client.add_scalar_value('rpn_loss', rpn_loss.avg, step=current_step)\n",
    "            tensorboard_client.add_scalar_value('cross_entropy', cross_entropy.avg, step=current_step)\n",
    "            tensorboard_client.add_scalar_value('loss_box', loss_box.avg, step=current_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_data_gen, optimizer, lr_scheduler ,model, epochs=10):\n",
    "    \n",
    "    exp_name = datetime.now().strftime('vgg16_%m-%d_%H-%Ms')\n",
    "    cc = CrayonClient(hostname=\"crayon\", port=8889)\n",
    "    exp = cc.create_experiment(exp_name)\n",
    "    \n",
    "    \n",
    "    train_loss = AverageMeter()\n",
    "    cross_entropy = AverageMeter()\n",
    "    loss_box = AverageMeter()\n",
    "    rpn_loss = AverageMeter()\n",
    "    metters = (train_loss , cross_entropy , loss_box, rpn_loss)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train(train_data_gen ,model, exp, metters, optimizer, lr_scheduler, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"faster_rcnn.utils.datasets.mscoco.dataset\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, '09/11_06:10')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"faster_rcnn.utils.datasets.mscoco.dataset\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, '09/11_06:10')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"faster_rcnn.utils.datasets.mscoco.dataset\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, '09/11_06:10')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"faster_rcnn.utils.datasets.mscoco.dataset\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(301, '09/11_06:10')\n",
      "(401, '09/11_06:10')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"faster_rcnn.utils.datasets.mscoco.dataset\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(501, '09/11_06:10')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"faster_rcnn.utils.datasets.mscoco.dataset\"\n",
      "No handlers could be found for logger \"faster_rcnn.utils.datasets.mscoco.dataset\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(601, '09/11_06:10')\n",
      "(701, '09/11_06:10')\n",
      "(801, '09/11_06:10')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"faster_rcnn.utils.datasets.mscoco.dataset\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(901, '09/11_06:10')\n",
      "(1001, '09/11_06:10')\n",
      "(1101, '09/11_06:11')\n",
      "(1201, '09/11_06:11')\n",
      "(1301, '09/11_06:11')\n",
      "(1401, '09/11_06:11')\n",
      "(1501, '09/11_06:11')\n",
      "(1601, '09/11_06:11')\n",
      "(1701, '09/11_06:11')\n",
      "(1801, '09/11_06:11')\n",
      "(1901, '09/11_06:11')\n",
      "(2001, '09/11_06:11')\n",
      "(2101, '09/11_06:11')\n",
      "(2201, '09/11_06:11')\n",
      "(2301, '09/11_06:11')\n",
      "(2401, '09/11_06:11')\n",
      "(2501, '09/11_06:12')\n",
      "(2601, '09/11_06:12')\n",
      "(2701, '09/11_06:12')\n",
      "(2801, '09/11_06:12')\n",
      "(2901, '09/11_06:12')\n",
      "(3001, '09/11_06:12')\n",
      "(3101, '09/11_06:12')\n",
      "(3201, '09/11_06:12')\n",
      "(3301, '09/11_06:12')\n",
      "(3401, '09/11_06:12')\n",
      "(3501, '09/11_06:12')\n",
      "(3601, '09/11_06:12')\n",
      "(3701, '09/11_06:12')\n",
      "(3801, '09/11_06:12')\n",
      "(3901, '09/11_06:12')\n",
      "(4001, '09/11_06:13')\n",
      "(4101, '09/11_06:13')\n",
      "(4201, '09/11_06:13')\n",
      "(4301, '09/11_06:13')\n",
      "(4401, '09/11_06:13')\n",
      "(4501, '09/11_06:13')\n",
      "(4601, '09/11_06:13')\n",
      "(4701, '09/11_06:13')\n",
      "(4801, '09/11_06:13')\n",
      "(4901, '09/11_06:13')\n",
      "(5001, '09/11_06:13')\n",
      "(5101, '09/11_06:13')\n",
      "(5201, '09/11_06:13')\n",
      "(5301, '09/11_06:13')\n",
      "(5401, '09/11_06:13')\n",
      "(5501, '09/11_06:14')\n",
      "(5601, '09/11_06:14')\n",
      "(5701, '09/11_06:14')\n",
      "(5801, '09/11_06:14')\n",
      "(5901, '09/11_06:14')\n",
      "(6001, '09/11_06:14')\n",
      "(6101, '09/11_06:14')\n",
      "(6201, '09/11_06:14')\n",
      "(6301, '09/11_06:14')\n",
      "(6401, '09/11_06:14')\n",
      "(6501, '09/11_06:14')\n",
      "(6601, '09/11_06:14')\n",
      "(6701, '09/11_06:14')\n",
      "(6801, '09/11_06:14')\n",
      "(6901, '09/11_06:15')\n",
      "(7001, '09/11_06:15')\n",
      "(7101, '09/11_06:15')\n",
      "(7201, '09/11_06:15')\n",
      "(7301, '09/11_06:15')\n",
      "(7401, '09/11_06:15')\n",
      "(7501, '09/11_06:15')\n",
      "(7601, '09/11_06:15')\n",
      "(7701, '09/11_06:15')\n",
      "(7801, '09/11_06:15')\n",
      "(7901, '09/11_06:15')\n",
      "(8001, '09/11_06:15')\n",
      "(8101, '09/11_06:15')\n",
      "(8201, '09/11_06:15')\n",
      "(8301, '09/11_06:16')\n",
      "(8401, '09/11_06:16')\n",
      "(8501, '09/11_06:16')\n",
      "(8601, '09/11_06:16')\n",
      "(8701, '09/11_06:16')\n",
      "(8801, '09/11_06:16')\n",
      "(8901, '09/11_06:16')\n",
      "(9001, '09/11_06:16')\n",
      "(9101, '09/11_06:16')\n",
      "(9201, '09/11_06:16')\n",
      "(9301, '09/11_06:16')\n",
      "(9401, '09/11_06:16')\n",
      "(9501, '09/11_06:16')\n",
      "(9601, '09/11_06:16')\n",
      "(9701, '09/11_06:16')\n",
      "(9801, '09/11_06:17')\n",
      "(9901, '09/11_06:17')\n",
      "(10001, '09/11_06:17')\n",
      "(10101, '09/11_06:17')\n",
      "(10201, '09/11_06:17')\n",
      "(10301, '09/11_06:17')\n",
      "(10401, '09/11_06:17')\n",
      "(10501, '09/11_06:17')\n",
      "(10601, '09/11_06:17')\n",
      "(10701, '09/11_06:17')\n",
      "(10801, '09/11_06:17')\n",
      "(10901, '09/11_06:17')\n",
      "(11001, '09/11_06:17')\n",
      "(11101, '09/11_06:17')\n",
      "(11201, '09/11_06:18')\n",
      "(11301, '09/11_06:18')\n",
      "(11401, '09/11_06:18')\n",
      "(11501, '09/11_06:18')\n",
      "(11601, '09/11_06:18')\n",
      "(11701, '09/11_06:18')\n",
      "(11801, '09/11_06:18')\n",
      "(11901, '09/11_06:18')\n",
      "(12001, '09/11_06:18')\n",
      "(12101, '09/11_06:18')\n",
      "(12201, '09/11_06:18')\n",
      "(12301, '09/11_06:18')\n",
      "(12401, '09/11_06:18')\n",
      "(12501, '09/11_06:18')\n",
      "(12601, '09/11_06:18')\n",
      "(12701, '09/11_06:19')\n",
      "(12801, '09/11_06:19')\n",
      "(12901, '09/11_06:19')\n",
      "(13001, '09/11_06:19')\n",
      "(13101, '09/11_06:19')\n",
      "(13201, '09/11_06:19')\n",
      "(13301, '09/11_06:19')\n",
      "(13401, '09/11_06:19')\n",
      "(13501, '09/11_06:19')\n",
      "(13601, '09/11_06:19')\n",
      "(13701, '09/11_06:19')\n",
      "(13801, '09/11_06:19')\n",
      "(13901, '09/11_06:19')\n",
      "(14001, '09/11_06:19')\n",
      "(14101, '09/11_06:19')\n",
      "(14201, '09/11_06:20')\n",
      "(14301, '09/11_06:20')\n",
      "(14401, '09/11_06:20')\n",
      "(14501, '09/11_06:20')\n",
      "(14601, '09/11_06:20')\n",
      "(14701, '09/11_06:20')\n",
      "(14801, '09/11_06:20')\n",
      "(14901, '09/11_06:20')\n",
      "(15001, '09/11_06:20')\n",
      "(15101, '09/11_06:20')\n",
      "(15201, '09/11_06:20')\n",
      "(15301, '09/11_06:20')\n",
      "(15401, '09/11_06:20')\n",
      "(15501, '09/11_06:20')\n",
      "(15601, '09/11_06:21')\n",
      "(15701, '09/11_06:21')\n",
      "(15801, '09/11_06:21')\n",
      "(15901, '09/11_06:21')\n",
      "(16001, '09/11_06:21')\n",
      "(16101, '09/11_06:21')\n",
      "(16201, '09/11_06:21')\n",
      "(16301, '09/11_06:21')\n",
      "(16401, '09/11_06:21')\n",
      "(16501, '09/11_06:21')\n",
      "(16601, '09/11_06:21')\n",
      "(16701, '09/11_06:21')\n",
      "(16801, '09/11_06:21')\n",
      "(16901, '09/11_06:21')\n",
      "(17001, '09/11_06:21')\n",
      "(17101, '09/11_06:22')\n",
      "(17201, '09/11_06:22')\n",
      "(17301, '09/11_06:22')\n",
      "(17401, '09/11_06:22')\n",
      "(17501, '09/11_06:22')\n",
      "(17601, '09/11_06:22')\n",
      "(17701, '09/11_06:22')\n",
      "(17801, '09/11_06:22')\n",
      "(17901, '09/11_06:22')\n",
      "(18001, '09/11_06:22')\n",
      "(18101, '09/11_06:22')\n",
      "(18201, '09/11_06:22')\n",
      "(18301, '09/11_06:22')\n",
      "(18401, '09/11_06:22')\n",
      "(18501, '09/11_06:23')\n",
      "(18601, '09/11_06:23')\n",
      "(18701, '09/11_06:23')\n",
      "(18801, '09/11_06:23')\n",
      "(18901, '09/11_06:23')\n",
      "(19001, '09/11_06:23')\n",
      "(19101, '09/11_06:23')\n",
      "(19201, '09/11_06:23')\n",
      "(19301, '09/11_06:23')\n",
      "(19401, '09/11_06:23')\n",
      "(19501, '09/11_06:23')\n",
      "(19601, '09/11_06:23')\n",
      "(19701, '09/11_06:23')\n",
      "(19801, '09/11_06:23')\n",
      "(19901, '09/11_06:23')\n",
      "(20001, '09/11_06:24')\n",
      "(20101, '09/11_06:24')\n",
      "(20201, '09/11_06:24')\n",
      "(20301, '09/11_06:24')\n",
      "(20401, '09/11_06:24')\n",
      "(20501, '09/11_06:24')\n",
      "(20601, '09/11_06:24')\n",
      "torch.Size([4, 3, 600, 1802])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1532571898140/work/aten/src/THC/generic/THCTensorMath.cu:35",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-aa48b8f5f1c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-760290f6901e>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(train_data_gen, optimizer, lr_scheduler, model, epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_gen\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-9c771061f628>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_gen, model, tensorboard_client, metters, optimizer, lr_scheduler, current_epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_boxes_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mbatch_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_boxes_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcross_entropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch/lib/python2.7/site-packages/torch/optim/optimizer.pyc\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1532571898140/work/aten/src/THC/generic/THCTensorMath.cu:35"
     ]
    }
   ],
   "source": [
    "training(train_data_loader ,optimizer=optimizer,lr_scheduler=exp_lr_scheduler, model=net, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('faster.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_boxes, scores, classes, rois, im_data = net.detect(\"./test7.jpg\", thr=0.5)\n",
    "print classes\n",
    "print scores\n",
    "print pred_boxes\n",
    "imshow(im_data[0],[] ,pred_boxes, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
