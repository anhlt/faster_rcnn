{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from faster_rcnn.utils.cython_bbox import bbox_overlaps\n",
    "from pycrayon import CrayonClient\n",
    "\n",
    "import cPickle\n",
    "from torch.optim import SGD, RMSprop, Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from datetime import datetime\n",
    "from faster_rcnn.utils.datasets.adapter import convert_data\n",
    "from faster_rcnn.utils.evaluate.metter import AverageMeter\n",
    "from faster_rcnn.utils.display.images import imshow, result_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sorted_index', 'rb') as fp:\n",
    "    sorted_index = cPickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đọc dữ liệu từ MS COCO dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_rcnn.utils.datasets.adapter import convert_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=9.97s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from faster_rcnn.utils.datasets.mscoco.dataset import CocoData\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "\n",
    "dataDir = './data/mscoco'\n",
    "dataType = 'train2014'\n",
    "annFile='%s/annotations/instances_%s.json'%(dataDir,dataType)\n",
    "batch_size = 4\n",
    "\n",
    "images_dir = os.path.join(dataDir,'images', dataType)\n",
    "cap = CocoData(root = images_dir, annFile = annFile,sorted_indexes=sorted_index)\n",
    "\n",
    "train_data_loader = DataLoader(cap, batch_size=batch_size, shuffle=False, collate_fn=convert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"faster_rcnn.utils.datasets.mscoco.dataset\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s=time.time()\n",
    "for i_batch, sample_batched in enumerate(train_data_loader):\n",
    "    print(i_batch)\n",
    "    if(i_batch > 200):\n",
    "        break\n",
    "    \n",
    "e=time.time()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gt_classes': tensor([ 28,   1], dtype=torch.int32), 'boxes': tensor([[  267.2986,   307.1090,   318.4834,   494.7867],\n",
      "        [   45.4976,    22.7488,   543.1280,  1401.8957]], dtype=torch.float64), 'tensor': tensor([[[[ 1.7352,  1.7352,  1.7352,  ...,  1.2728,  1.2728,  1.2728],\n",
      "          [ 1.7352,  1.7352,  1.7352,  ...,  1.2728,  1.2728,  1.2728],\n",
      "          [ 1.7352,  1.7352,  1.7352,  ...,  1.2728,  1.2728,  1.2728],\n",
      "          ...,\n",
      "          [ 0.6049,  0.6049,  0.6049,  ...,  0.6563,  0.6563,  0.6563],\n",
      "          [ 0.6049,  0.6049,  0.6049,  ...,  0.6563,  0.6563,  0.6563],\n",
      "          [ 0.6049,  0.6049,  0.6049,  ...,  0.6563,  0.6563,  0.6563]],\n",
      "\n",
      "         [[ 1.9209,  1.9209,  1.9209,  ...,  1.5182,  1.5182,  1.5182],\n",
      "          [ 1.9209,  1.9209,  1.9209,  ...,  1.5182,  1.5182,  1.5182],\n",
      "          [ 1.9209,  1.9209,  1.9209,  ...,  1.5182,  1.5182,  1.5182],\n",
      "          ...,\n",
      "          [ 0.8354,  0.8354,  0.8354,  ...,  0.8880,  0.8880,  0.8880],\n",
      "          [ 0.8354,  0.8354,  0.8354,  ...,  0.8880,  0.8880,  0.8880],\n",
      "          [ 0.8354,  0.8354,  0.8354,  ...,  0.8880,  0.8880,  0.8880]],\n",
      "\n",
      "         [[ 2.0474,  2.0474,  2.0474,  ...,  1.7860,  1.7860,  1.7860],\n",
      "          [ 2.0474,  2.0474,  2.0474,  ...,  1.7860,  1.7860,  1.7860],\n",
      "          [ 2.0474,  2.0474,  2.0474,  ...,  1.7860,  1.7860,  1.7860],\n",
      "          ...,\n",
      "          [ 1.1237,  1.1237,  1.1237,  ...,  1.1759,  1.1759,  1.1759],\n",
      "          [ 1.1237,  1.1237,  1.1237,  ...,  1.1759,  1.1759,  1.1759],\n",
      "          [ 1.1237,  1.1237,  1.1237,  ...,  1.1759,  1.1759,  1.1759]]]]), 'im_info': tensor([[ 1421.0000,   600.0000,     2.8436]])}\n"
     ]
    }
   ],
   "source": [
    "print cap[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=7.96s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataDir = './data/mscoco'\n",
    "dataType = 'val2014'\n",
    "annFile='%s/annotations/instances_%s.json'%(dataDir,dataType)\n",
    "batch_size = 6\n",
    "\n",
    "images_dir = os.path.join(dataDir,'images', dataType)\n",
    "val_cap = CocoData(root = images_dir, annFile = annFile)\n",
    "\n",
    "val_data_loader = DataLoader(val_cap, batch_size=4, shuffle=False, collate_fn=default_collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thử hiển thị ảnh cùng các bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from faster_rcnn.faster_rcnn import FastRCNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tính toán feed-forward\n",
    "\n",
    "\n",
    "Chúng ta sử dụng một ảnh có kích thước đầu vào là  `(width , height) = (600, 800)`\n",
    "\n",
    "Input:\n",
    "    - im_data : \n",
    "        kích thước : (batch_size, dim, witdh, height)\n",
    "    - ground_boxes: \n",
    "        kích thước (n, 4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['__background__'] + [x['name'] for x in cap.coco.loadCats(cap.coco.getCatIds())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python2.7/site-packages/torch/nn/parallel/data_parallel.py:24: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FastRCNN(\n",
       "  (rpn): RPN(\n",
       "    (features): DataParallel(\n",
       "      (module): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU(inplace)\n",
       "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): ReLU(inplace)\n",
       "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (8): ReLU(inplace)\n",
       "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (11): ReLU(inplace)\n",
       "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (13): ReLU(inplace)\n",
       "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (15): ReLU(inplace)\n",
       "        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (18): ReLU(inplace)\n",
       "        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (20): ReLU(inplace)\n",
       "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (22): ReLU(inplace)\n",
       "        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (25): ReLU(inplace)\n",
       "        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (27): ReLU(inplace)\n",
       "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (29): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (conv1): DataParallel(\n",
       "      (module): Conv2d(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (score_conv): DataParallel(\n",
       "      (module): Conv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (bbox_conv): DataParallel(\n",
       "      (module): Conv2d(\n",
       "        (conv): Conv2d(512, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (anchor_target_layer): AnchorTargerLayer()\n",
       "    (proposal_layer): ProposalLayer()\n",
       "  )\n",
       "  (proposal_target_layer): ProposalTargetLayer()\n",
       "  (roi_pool): RoIPool()\n",
       "  (fc6): DataParallel(\n",
       "    (module): FC(\n",
       "      (fc): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (fc7): DataParallel(\n",
       "    (module): FC(\n",
       "      (fc): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (score_fc): DataParallel(\n",
       "    (module): FC(\n",
       "      (fc): Linear(in_features=4096, out_features=81, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (bbox_fc): DataParallel(\n",
       "    (module): FC(\n",
       "      (fc): Linear(in_features=4096, out_features=324, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FastRCNN(categories, debug=False)\n",
    "net.cuda()\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = filter(lambda x: x.requires_grad, net.parameters())\n",
    "optimizer = SGD(param, lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
    "exp_lr_scheduler = StepLR(optimizer, step_size=1000, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_gen ,model, steps_per_epoch=2000, epochs=1):\n",
    "    model.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    val_cross_entropy = AverageMeter()\n",
    "    val_loss_box = AverageMeter()\n",
    "    val_rpn_loss = AverageMeter()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for step in range(1, steps_per_epoch +1):\n",
    "            blobs = data_gen.next()\n",
    "            batch_tensor, im_info, batch_boxes, batch_boxes_index = convert_data(blobs)\n",
    "            cls_prob, bbox_pred, rois = model(batch_tensor, im_info, batch_boxes, batch_boxes_index)\n",
    "\n",
    "            loss = model.loss\n",
    "            \n",
    "            val_loss_box.update(model.loss_box.item())\n",
    "            val_cross_entropy.update(model.cross_entropy.item())\n",
    "            val_loss.update(loss.item())\n",
    "            val_rpn_loss.update(model.rpn.loss.item())\n",
    "    \n",
    "    log_text = 'val_loss: %.4f' % (val_loss.avg)\n",
    "    print(log_text)\n",
    "    return val_loss ,val_cross_entropy, val_loss_box, val_rpn_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data_gen, val_data_gen, optimizer, lr_scheduler ,model, epochs, steps_per_epoch, val_step_per_epoch):\n",
    "    \n",
    "    exp_name = datetime.now().strftime('vgg16_%m-%d_%H-%M')\n",
    "    cc = CrayonClient(hostname=\"crayon\", port=8889)\n",
    "    exp = cc.create_experiment(exp_name)\n",
    "    \n",
    "    \n",
    "    train_loss = AverageMeter()\n",
    "    cross_entropy = AverageMeter()\n",
    "    loss_box = AverageMeter()\n",
    "    rpn_loss = AverageMeter()\n",
    "    current_step = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for step in range(1, steps_per_epoch +1):\n",
    "            lr_scheduler.step()        \n",
    "            blobs = data_gen.next()\n",
    "            batch_tensor, im_info, batch_boxes, batch_boxes_index = convert_data(blobs)\n",
    "\n",
    "            cls_prob, bbox_pred, rois = model(batch_tensor, im_info, batch_boxes, batch_boxes_index)\n",
    "            cls_data = cls_prob.data.cpu().numpy()\n",
    "            max_class_idx = np.argmax(cls_data, axis=1)\n",
    "            loss = model.loss\n",
    "            cross_entropy.update(model.cross_entropy.item())\n",
    "            loss_box.update(model.loss_box.item())\n",
    "            train_loss.update(loss.item())\n",
    "            rpn_loss.update(model.rpn.loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            current_step = epoch * steps_per_epoch + step\n",
    "            if step % 20 == 1:\n",
    "                log_text = 'epoch: %d : step %d,  loss: %.4f at %s' % (\n",
    "                    epoch + 1, step , train_loss.avg, datetime.now().strftime('%m\\%d_%H:%M'))\n",
    "                print(log_text)\n",
    "\n",
    "            if step % 20 == 0:\n",
    "                exp.add_scalar_value('train_loss', train_loss.avg, step=current_step)\n",
    "                exp.add_scalar_value('rpn_loss', rpn_loss.avg, step=current_step)\n",
    "                exp.add_scalar_value('cross_entropy', cross_entropy.avg, step=current_step)\n",
    "                exp.add_scalar_value('loss_box', loss_box.avg, step=current_step)\n",
    "\n",
    "\n",
    "                \n",
    "        torch.save(model.state_dict(), './checkpoints/faster_model_at_epoch_%s.pkl' % (epoch + 1)) \n",
    "        val_loss ,val_cross_entropy, val_loss_box, val_rpn_loss = evaluate(val_data_gen, model, val_step_per_epoch)\n",
    "        exp.add_scalar_value('val_loss', val_loss.avg, step=current_step)\n",
    "        exp.add_scalar_value('val_rpn_loss', val_rpn_loss.avg, step=current_step)\n",
    "        exp.add_scalar_value('val_cross_entropy', val_cross_entropy.avg, step=current_step)\n",
    "        exp.add_scalar_value('val_loss_box', val_loss_box.avg, step=current_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_data_generator, val_data_generator ,optimizer=optimizer,lr_scheduler=exp_lr_scheduler, model=net, epochs=200, steps_per_epoch=6000, val_step_per_epoch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('faster.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_boxes, scores, classes, rois, im_data = net.detect(\"./test7.jpg\", thr=0.5)\n",
    "print classes\n",
    "print scores\n",
    "print pred_boxes\n",
    "imshow(im_data[0],[] ,pred_boxes, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
