{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from layers import Affine\n",
    "from layers.affine import AffineFunction\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_utils import get_CIFAR10_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = get_CIFAR10_data('../data/cifar-10-batches-py/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.FloatTensor\n",
    "num_inputs = 2\n",
    "input_shape = (4, 5, 6)\n",
    "output_dim = 3\n",
    "\n",
    "input_size = num_inputs * np.prod(input_shape)\n",
    "weight_size = output_dim * np.prod(input_shape)\n",
    "print weight_size\n",
    "print input_size\n",
    "\n",
    "x = np.linspace(-0.1, 0.5, num=input_size).reshape(num_inputs, *input_shape).astype(np.float32)\n",
    "w = np.linspace(-0.2, 0.3, num=weight_size).reshape(np.prod(input_shape), output_dim).astype(np.float32)\n",
    "b = np.linspace(-0.3, 0.1, num=output_dim).astype(np.float32)\n",
    "y = np.random.uniform(low=0, high=1, size=(3, 2)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Var_x = Variable(torch.from_numpy(x), requires_grad=True)\n",
    "Var_w = Variable(torch.from_numpy(w), requires_grad=True)\n",
    "Var_b = Variable(torch.from_numpy(b), requires_grad=True)\n",
    "Var_y = Variable(torch.from_numpy(y))\n",
    "affine = Affine(np.prod(input_shape), output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.2624 -0.0270  0.0996\n",
      "-0.1881  0.0981  0.3034\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = affine(Var_x)\n",
    "print result\n",
    "loss = (result - Var_y).pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-684559e268b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'backward should be called only on a scalar (i.e. 1-element tensor) or with gradient w.r.t. the variable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_as_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execution_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python2.7/site-packages/torch/autograd/function.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, *grad_output)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 5, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Var_x.grad.data.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-2.8822\n",
       "-2.8870\n",
       "-3.8362\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affine.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.2537 -0.2502 -0.1268\n",
       "-0.2610 -0.2574 -0.1364\n",
       "-0.2682 -0.2647 -0.1461\n",
       "-0.2754 -0.2719 -0.1557\n",
       "-0.2827 -0.2792 -0.1653\n",
       "-0.2899 -0.2864 -0.1750\n",
       "-0.2971 -0.2937 -0.1846\n",
       "-0.3044 -0.3009 -0.1942\n",
       "-0.3116 -0.3082 -0.2039\n",
       "-0.3188 -0.3154 -0.2135\n",
       "-0.3261 -0.3226 -0.2231\n",
       "-0.3333 -0.3299 -0.2327\n",
       "-0.3406 -0.3371 -0.2424\n",
       "-0.3478 -0.3444 -0.2520\n",
       "-0.3550 -0.3516 -0.2616\n",
       "-0.3623 -0.3589 -0.2713\n",
       "-0.3695 -0.3661 -0.2809\n",
       "-0.3767 -0.3734 -0.2905\n",
       "-0.3840 -0.3806 -0.3002\n",
       "-0.3912 -0.3879 -0.3098\n",
       "-0.3984 -0.3951 -0.3194\n",
       "-0.4057 -0.4024 -0.3291\n",
       "-0.4129 -0.4096 -0.3387\n",
       "-0.4201 -0.4169 -0.3483\n",
       "-0.4274 -0.4241 -0.3579\n",
       "-0.4346 -0.4314 -0.3676\n",
       "-0.4419 -0.4386 -0.3772\n",
       "-0.4491 -0.4459 -0.3868\n",
       "-0.4563 -0.4531 -0.3965\n",
       "-0.4636 -0.4604 -0.4061\n",
       "-0.4708 -0.4676 -0.4157\n",
       "-0.4780 -0.4748 -0.4254\n",
       "-0.4853 -0.4821 -0.4350\n",
       "-0.4925 -0.4893 -0.4446\n",
       "-0.4997 -0.4966 -0.4543\n",
       "-0.5070 -0.5038 -0.4639\n",
       "-0.5142 -0.5111 -0.4735\n",
       "-0.5214 -0.5183 -0.4831\n",
       "-0.5287 -0.5256 -0.4928\n",
       "-0.5359 -0.5328 -0.5024\n",
       "-0.5432 -0.5401 -0.5120\n",
       "-0.5504 -0.5473 -0.5217\n",
       "-0.5576 -0.5546 -0.5313\n",
       "-0.5649 -0.5618 -0.5409\n",
       "-0.5721 -0.5691 -0.5506\n",
       "-0.5793 -0.5763 -0.5602\n",
       "-0.5866 -0.5836 -0.5698\n",
       "-0.5938 -0.5908 -0.5794\n",
       "-0.6010 -0.5981 -0.5891\n",
       "-0.6083 -0.6053 -0.5987\n",
       "-0.6155 -0.6126 -0.6083\n",
       "-0.6227 -0.6198 -0.6180\n",
       "-0.6300 -0.6270 -0.6276\n",
       "-0.6372 -0.6343 -0.6372\n",
       "-0.6444 -0.6415 -0.6469\n",
       "-0.6517 -0.6488 -0.6565\n",
       "-0.6589 -0.6560 -0.6661\n",
       "-0.6662 -0.6633 -0.6758\n",
       "-0.6734 -0.6705 -0.6854\n",
       "-0.6806 -0.6778 -0.6950\n",
       "-0.6879 -0.6850 -0.7046\n",
       "-0.6951 -0.6923 -0.7143\n",
       "-0.7023 -0.6995 -0.7239\n",
       "-0.7096 -0.7068 -0.7335\n",
       "-0.7168 -0.7140 -0.7432\n",
       "-0.7240 -0.7213 -0.7528\n",
       "-0.7313 -0.7285 -0.7624\n",
       "-0.7385 -0.7358 -0.7721\n",
       "-0.7457 -0.7430 -0.7817\n",
       "-0.7530 -0.7503 -0.7913\n",
       "-0.7602 -0.7575 -0.8010\n",
       "-0.7675 -0.7648 -0.8106\n",
       "-0.7747 -0.7720 -0.8202\n",
       "-0.7819 -0.7792 -0.8298\n",
       "-0.7892 -0.7865 -0.8395\n",
       "-0.7964 -0.7937 -0.8491\n",
       "-0.8036 -0.8010 -0.8587\n",
       "-0.8109 -0.8082 -0.8684\n",
       "-0.8181 -0.8155 -0.8780\n",
       "-0.8253 -0.8227 -0.8876\n",
       "-0.8326 -0.8300 -0.8973\n",
       "-0.8398 -0.8372 -0.9069\n",
       "-0.8470 -0.8445 -0.9165\n",
       "-0.8543 -0.8517 -0.9262\n",
       "-0.8615 -0.8590 -0.9358\n",
       "-0.8688 -0.8662 -0.9454\n",
       "-0.8760 -0.8735 -0.9550\n",
       "-0.8832 -0.8807 -0.9647\n",
       "-0.8905 -0.8880 -0.9743\n",
       "-0.8977 -0.8952 -0.9839\n",
       "-0.9049 -0.9025 -0.9936\n",
       "-0.9122 -0.9097 -1.0032\n",
       "-0.9194 -0.9170 -1.0128\n",
       "-0.9266 -0.9242 -1.0225\n",
       "-0.9339 -0.9314 -1.0321\n",
       "-0.9411 -0.9387 -1.0417\n",
       "-0.9483 -0.9459 -1.0513\n",
       "-0.9556 -0.9532 -1.0610\n",
       "-0.9628 -0.9604 -1.0706\n",
       "-0.9701 -0.9677 -1.0802\n",
       "-0.9773 -0.9749 -1.0899\n",
       "-0.9845 -0.9822 -1.0995\n",
       "-0.9918 -0.9894 -1.1091\n",
       "-0.9990 -0.9967 -1.1188\n",
       "-1.0062 -1.0039 -1.1284\n",
       "-1.0135 -1.0112 -1.1380\n",
       "-1.0207 -1.0184 -1.1477\n",
       "-1.0279 -1.0257 -1.1573\n",
       "-1.0352 -1.0329 -1.1669\n",
       "-1.0424 -1.0402 -1.1765\n",
       "-1.0496 -1.0474 -1.1862\n",
       "-1.0569 -1.0547 -1.1958\n",
       "-1.0641 -1.0619 -1.2054\n",
       "-1.0714 -1.0692 -1.2151\n",
       "-1.0786 -1.0764 -1.2247\n",
       "-1.0858 -1.0836 -1.2343\n",
       "-1.0931 -1.0909 -1.2440\n",
       "-1.1003 -1.0981 -1.2536\n",
       "-1.1075 -1.1054 -1.2632\n",
       "-1.1148 -1.1126 -1.2729\n",
       "[torch.FloatTensor of size 120x3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affine.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
