{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from layers import Affine\n",
    "from layers.affine import AffineFunction\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data.sampler import RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_utils import get_CIFAR10_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = get_CIFAR10_data('../data/cifar-10-batches-py/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 3, 32, 32)\n",
      "(49000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = data['X_train']\n",
    "y_train = data['y_train'].flatten()\n",
    "\n",
    "\n",
    "\n",
    "print(data['X_train'].shape)\n",
    "print(data['y_train'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# y_tmp = np.zeros((49000, 10))\n",
    "# y_tmp[np.arange(49000), y_train] = 1\n",
    "# y_train = y_tmp\n",
    "# print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "data_loader = DataLoader(dataset,batch_size=30 , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(500, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(x.size(0), -1 )\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net (\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d (p=0.5)\n",
       "  (fc1): Linear (500 -> 50)\n",
       "  (fc2): Linear (50 -> 10)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for batch_idx, (data, target) in enumerate(data_loader):\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    output = model(data)\n",
    "    break\n",
    "    \n",
    "from torch.utils.data.dataloader import DataLoaderIter\n",
    "data_loader_iter = DataLoaderIter(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from solver import Solver \n",
    "solver = Solver(model,\n",
    "                dataset, \n",
    "                optimizer='SGD', \n",
    "                optim_config={\"lr\":1e-3, \"momentum\":True}, \n",
    "                batch_size=100, \n",
    "                num_epochs=1, \n",
    "                print_every=1,\n",
    "                loss=torch.nn.CrossEntropyLoss\n",
    "               )\n",
    "solver.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4, 5, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Var_x.grad.data.numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.1932\n",
       "-4.0843\n",
       "-1.9454\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affine.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0206 -0.2811  0.1573\n",
       " 0.0201 -0.2914  0.1524\n",
       " 0.0196 -0.3016  0.1475\n",
       " 0.0191 -0.3119  0.1426\n",
       " 0.0186 -0.3221  0.1377\n",
       " 0.0182 -0.3324  0.1328\n",
       " 0.0177 -0.3426  0.1280\n",
       " 0.0172 -0.3529  0.1231\n",
       " 0.0167 -0.3631  0.1182\n",
       " 0.0162 -0.3734  0.1133\n",
       " 0.0157 -0.3836  0.1084\n",
       " 0.0153 -0.3939  0.1035\n",
       " 0.0148 -0.4042  0.0987\n",
       " 0.0143 -0.4144  0.0938\n",
       " 0.0138 -0.4247  0.0889\n",
       " 0.0133 -0.4349  0.0840\n",
       " 0.0128 -0.4452  0.0791\n",
       " 0.0123 -0.4554  0.0742\n",
       " 0.0119 -0.4657  0.0693\n",
       " 0.0114 -0.4759  0.0645\n",
       " 0.0109 -0.4862  0.0596\n",
       " 0.0104 -0.4964  0.0547\n",
       " 0.0099 -0.5067  0.0498\n",
       " 0.0094 -0.5169  0.0449\n",
       " 0.0089 -0.5272  0.0400\n",
       " 0.0085 -0.5374  0.0352\n",
       " 0.0080 -0.5477  0.0303\n",
       " 0.0075 -0.5580  0.0254\n",
       " 0.0070 -0.5682  0.0205\n",
       " 0.0065 -0.5785  0.0156\n",
       " 0.0060 -0.5887  0.0107\n",
       " 0.0056 -0.5990  0.0059\n",
       " 0.0051 -0.6092  0.0010\n",
       " 0.0046 -0.6195 -0.0039\n",
       " 0.0041 -0.6297 -0.0088\n",
       " 0.0036 -0.6400 -0.0137\n",
       " 0.0031 -0.6502 -0.0186\n",
       " 0.0026 -0.6605 -0.0234\n",
       " 0.0022 -0.6707 -0.0283\n",
       " 0.0017 -0.6810 -0.0332\n",
       " 0.0012 -0.6913 -0.0381\n",
       " 0.0007 -0.7015 -0.0430\n",
       " 0.0002 -0.7118 -0.0479\n",
       "-0.0003 -0.7220 -0.0527\n",
       "-0.0008 -0.7323 -0.0576\n",
       "-0.0012 -0.7425 -0.0625\n",
       "-0.0017 -0.7528 -0.0674\n",
       "-0.0022 -0.7630 -0.0723\n",
       "-0.0027 -0.7733 -0.0772\n",
       "-0.0032 -0.7835 -0.0821\n",
       "-0.0037 -0.7938 -0.0869\n",
       "-0.0042 -0.8040 -0.0918\n",
       "-0.0046 -0.8143 -0.0967\n",
       "-0.0051 -0.8245 -0.1016\n",
       "-0.0056 -0.8348 -0.1065\n",
       "-0.0061 -0.8451 -0.1114\n",
       "-0.0066 -0.8553 -0.1162\n",
       "-0.0071 -0.8656 -0.1211\n",
       "-0.0075 -0.8758 -0.1260\n",
       "-0.0080 -0.8861 -0.1309\n",
       "-0.0085 -0.8963 -0.1358\n",
       "-0.0090 -0.9066 -0.1407\n",
       "-0.0095 -0.9168 -0.1455\n",
       "-0.0100 -0.9271 -0.1504\n",
       "-0.0105 -0.9373 -0.1553\n",
       "-0.0109 -0.9476 -0.1602\n",
       "-0.0114 -0.9578 -0.1651\n",
       "-0.0119 -0.9681 -0.1700\n",
       "-0.0124 -0.9783 -0.1748\n",
       "-0.0129 -0.9886 -0.1797\n",
       "-0.0134 -0.9989 -0.1846\n",
       "-0.0139 -1.0091 -0.1895\n",
       "-0.0143 -1.0194 -0.1944\n",
       "-0.0148 -1.0296 -0.1993\n",
       "-0.0153 -1.0399 -0.2041\n",
       "-0.0158 -1.0501 -0.2090\n",
       "-0.0163 -1.0604 -0.2139\n",
       "-0.0168 -1.0706 -0.2188\n",
       "-0.0172 -1.0809 -0.2237\n",
       "-0.0177 -1.0911 -0.2286\n",
       "-0.0182 -1.1014 -0.2334\n",
       "-0.0187 -1.1116 -0.2383\n",
       "-0.0192 -1.1219 -0.2432\n",
       "-0.0197 -1.1322 -0.2481\n",
       "-0.0202 -1.1424 -0.2530\n",
       "-0.0206 -1.1527 -0.2579\n",
       "-0.0211 -1.1629 -0.2628\n",
       "-0.0216 -1.1732 -0.2676\n",
       "-0.0221 -1.1834 -0.2725\n",
       "-0.0226 -1.1937 -0.2774\n",
       "-0.0231 -1.2039 -0.2823\n",
       "-0.0236 -1.2142 -0.2872\n",
       "-0.0240 -1.2244 -0.2921\n",
       "-0.0245 -1.2347 -0.2969\n",
       "-0.0250 -1.2449 -0.3018\n",
       "-0.0255 -1.2552 -0.3067\n",
       "-0.0260 -1.2654 -0.3116\n",
       "-0.0265 -1.2757 -0.3165\n",
       "-0.0270 -1.2860 -0.3214\n",
       "-0.0274 -1.2962 -0.3262\n",
       "-0.0279 -1.3065 -0.3311\n",
       "-0.0284 -1.3167 -0.3360\n",
       "-0.0289 -1.3270 -0.3409\n",
       "-0.0294 -1.3372 -0.3458\n",
       "-0.0299 -1.3475 -0.3507\n",
       "-0.0303 -1.3577 -0.3555\n",
       "-0.0308 -1.3680 -0.3604\n",
       "-0.0313 -1.3782 -0.3653\n",
       "-0.0318 -1.3885 -0.3702\n",
       "-0.0323 -1.3987 -0.3751\n",
       "-0.0328 -1.4090 -0.3800\n",
       "-0.0333 -1.4193 -0.3848\n",
       "-0.0337 -1.4295 -0.3897\n",
       "-0.0342 -1.4398 -0.3946\n",
       "-0.0347 -1.4500 -0.3995\n",
       "-0.0352 -1.4603 -0.4044\n",
       "-0.0357 -1.4705 -0.4093\n",
       "-0.0362 -1.4808 -0.4141\n",
       "-0.0367 -1.4910 -0.4190\n",
       "-0.0371 -1.5013 -0.4239\n",
       "[torch.FloatTensor of size 120x3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affine.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
